{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AnnaGhost2713/daia-eon.git\n",
        "%cd daia-eon/piiranha_refinement"
      ],
      "metadata": {
        "id": "CkxBPbGRQdqJ",
        "outputId": "b336217a-d214-4ffc-f025-06e03b141935",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "CkxBPbGRQdqJ",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'daia-eon'...\n",
            "remote: Enumerating objects: 857, done.\u001b[K\n",
            "remote: Counting objects: 100% (857/857), done.\u001b[K\n",
            "remote: Compressing objects: 100% (631/631), done.\u001b[K\n",
            "remote: Total 857 (delta 451), reused 596 (delta 218), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (857/857), 3.05 MiB | 2.70 MiB/s, done.\n",
            "Resolving deltas: 100% (451/451), done.\n",
            "/content/daia-eon/notebooks/daia-eon/piiranha_refinement\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"de_core_news_sm\")"
      ],
      "metadata": {
        "id": "eQcIbS-pQV-x"
      },
      "id": "eQcIbS-pQV-x",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "3ddec6a3",
      "metadata": {
        "id": "3ddec6a3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import re\n",
        "import spacy\n",
        "import json\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdc6cb4d",
      "metadata": {
        "id": "fdc6cb4d"
      },
      "source": [
        "Label Mapping der einzelnen Identifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "45473a6b",
      "metadata": {
        "id": "45473a6b"
      },
      "outputs": [],
      "source": [
        "# üìå Priorit√§t definieren: je h√∂her, desto st√§rker\n",
        "PRIORITY_MAP = {\n",
        "    \"regex\": 3,\n",
        "    \"piiranha\": 1,\n",
        "    \"spacy\": 2\n",
        "}\n",
        "\n",
        "TARGET_LABELS = [\"TITEL\", \"VORNAME\", \"NACHNAME\", \"FIRMA\", \"TELEFONNUMMER\", \"EMAIL\", \"FAX\", \"STRASSE\",\n",
        "                 \"HAUSNUMMER\", \"POSTLEITZAHL\", \"WOHNORT\", \"Z√ÑHLERNUMMER\", \"Z√ÑHLERSTAND\", \"VERTRAGSNUMMER\",\n",
        "                 \"ZAHLUNG\", \"BANK\", \"IBAN\", \"BIC\", \"DATUM\", \"GESENDET_MIT\", \"LINK\"]\n",
        "\n",
        "\n",
        "LABEL_MAP = {\n",
        "    # spaCy-Labels\n",
        "    \"PER\": \"NAME\", \"LOC\": \"ADRESSE\", \"ORG\": \"FIRMA\", \"DATE\": \"DATUM\", \"TIME\": \"DATUM\",\n",
        "    \"GPE\": \"ADRESSE\", \"NORP\": \"GRUPPE\", \"MONEY\": \"ZAHLUNG\",\n",
        "\n",
        "    # PIIranha-Labels\n",
        "    \"I-GIVENNAME\": \"NAME\", \"I-SURNAME\": \"NAME\", \"I-DATEOFBIRTH\": \"DATUM\",\n",
        "    \"I-EMAIL\": \"KONTAKT\", \"I-TELEPHONENUM\": \"KONTAKT\", \"I-USERNAME\": \"KONTAKT\",\n",
        "    \"I-CREDITCARDNUMBER\": \"ZAHLUNG\",\n",
        "    \"I-ACCOUNTNUM\": \"VERTRAG\", \"I-BILLINGNUM\": \"VERTRAG\",\n",
        "    \"I-IDCARDNUM\": \"VERTRAG\", \"I-TAXNUM\": \"VERTRAG\",\n",
        "    \"I-CITY\": \"ADRESSE\", \"I-ZIPCODE\": \"ADRESSE\", \"I-STREET\": \"ADRESSE\", \"I-BUILDINGNUM\": \"ADRESSE\",\n",
        "}\n",
        "\n",
        "REGEX_PATTERNS = {\n",
        "    \"KONTAKT\": r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+|\\+49[\\d\\s\\-\\(\\)]+\" ,\n",
        "    \"VERTRAG\": r\"\\b\\d{9,10}\\b|4\\s?0(?:\\s?\\d){7}\",\n",
        "    \"ZAHLUNG\": r\"\\b\\d{1,5},\\d{2}\\s?(‚Ç¨|Euro|Cent)?\\b\",\n",
        "    \"IBAN\": r\"DE\\d{20}\",\n",
        "    \"DATUM\": (\n",
        "        r\"\\b\\d{1,2}\\.\\d{1,2}\\.\\d{4}\\b|\"  # 15.08.2024\n",
        "        r\"\\b\\d{1,2}\\s+(Januar|Februar|M√§rz|April|Mai|Juni|Juli|August|\"\n",
        "        r\"September|Oktober|November|Dezember)\\s+\\d{4}\\b|\"  # 15 August 2024\n",
        "        r\"\\b\\d{1,2}\\.\\s+(Januar|Februar|M√§rz|April|Mai|Juni|Juli|August|\"\n",
        "        r\"September|Oktober|November|Dezember)\\s+\\d{4}\\b|\"  # 15. August 2024\n",
        "        r\"\\b(Januar|Februar|M√§rz|April|Mai|Juni|Juli|August|\"\n",
        "        r\"September|Oktober|November|Dezember)\\b|\"          # August\n",
        "        r\"\\b(19|20)\\d{2}\\b\"                                 # Jahreszahlen wie 2023\n",
        "    )\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4cc5acd",
      "metadata": {
        "id": "f4cc5acd"
      },
      "source": [
        "PIIranha Spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12368595",
      "metadata": {
        "id": "12368595"
      },
      "outputs": [],
      "source": [
        "model_name = \"iiiorg/piiranha-v1-detect-personal-information\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def get_piiranha_spans(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, return_offsets_mapping=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")[0].tolist()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)[0].tolist()\n",
        "\n",
        "    spans = []\n",
        "    current_label = None\n",
        "    current_start = None\n",
        "\n",
        "    for i, (start, end) in enumerate(offset_mapping):\n",
        "        if start == end:  # Special tokens\n",
        "            continue\n",
        "\n",
        "        raw_label = model.config.id2label[predictions[i]]\n",
        "        mapped_label = LABEL_MAP.get(raw_label, None)\n",
        "\n",
        "        if mapped_label in TARGET_LABELS:\n",
        "            if current_label == mapped_label:\n",
        "                continue  # Laufzeit verl√§ngert sich bis label endet\n",
        "            else:\n",
        "                # Wenn neuer Start: alten Span abschlie√üen\n",
        "                if current_label is not None:\n",
        "                    spans.append({\"start\": current_start, \"end\": offset_mapping[i-1][1], \"label\": current_label})\n",
        "                current_label = mapped_label\n",
        "                current_start = start\n",
        "        else:\n",
        "            if current_label is not None:\n",
        "                spans.append({\"start\": current_start, \"end\": offset_mapping[i-1][1], \"label\": current_label})\n",
        "                current_label = None\n",
        "                current_start = None\n",
        "\n",
        "    # Letzten Span abschlie√üen\n",
        "    if current_label is not None:\n",
        "        spans.append({\"start\": current_start, \"end\": offset_mapping[-1][1], \"label\": current_label})\n",
        "\n",
        "    return spans\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "899f7f6a",
      "metadata": {
        "id": "899f7f6a"
      },
      "source": [
        "SpaCy Spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b396a76",
      "metadata": {
        "id": "4b396a76"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"de_core_news_sm\")\n",
        "\n",
        "def get_spacy_spans(text):\n",
        "    doc = nlp(text)\n",
        "    spans = []\n",
        "    for ent in doc.ents:\n",
        "        label = LABEL_MAP.get(ent.label_, ent.label_)\n",
        "        if label in TARGET_LABELS:\n",
        "            spans.append({\"start\": ent.start_char, \"end\": ent.end_char, \"label\": label})\n",
        "    return spans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e73e8a11",
      "metadata": {
        "id": "e73e8a11"
      },
      "source": [
        "Regex Spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d80d052d",
      "metadata": {
        "id": "d80d052d"
      },
      "outputs": [],
      "source": [
        "def get_regex_spans(text):\n",
        "    spans = []\n",
        "    for raw_label, pattern in REGEX_PATTERNS.items():\n",
        "        mapped_label = LABEL_MAP.get(raw_label, raw_label)  # bleibt bei IBAN = IBAN\n",
        "        if mapped_label not in TARGET_LABELS:\n",
        "            continue\n",
        "        for match in re.finditer(pattern, text):\n",
        "            spans.append({\n",
        "                \"start\": match.start(),\n",
        "                \"end\": match.end(),\n",
        "                \"label\": mapped_label\n",
        "            })\n",
        "    return spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9833fe90",
      "metadata": {
        "id": "9833fe90",
        "outputId": "add03921-f577-4f08-a1c8-8a4b994dfb1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'start': 47, 'end': 58, 'label': 'VERTRAG'}, {'start': 102, 'end': 113, 'label': 'KONTAKT'}, {'start': 118, 'end': 135, 'label': 'KONTAKT'}]\n",
            "[{'start': 20, 'end': 28, 'label': 'NAME'}]\n",
            "[{'start': 103, 'end': 113, 'label': 'KONTAKT'}, {'start': 119, 'end': 134, 'label': 'KONTAKT'}, {'start': 48, 'end': 58, 'label': 'VERTRAG'}, {'start': 154, 'end': 159, 'label': 'ZAHLUNG'}, {'start': 171, 'end': 186, 'label': 'DATUM'}]\n"
          ]
        }
      ],
      "source": [
        "# Beispieltext zum Testen\n",
        "sample_text = \"\"\"\n",
        "Sehr geehrter Herr John Doe,\n",
        "Ihre Kundennummer 4012345678 ist aktiv.\n",
        "Bitte kontaktieren Sie uns unter max@eon.de oder +49 171 1234567.\n",
        "Ihre Zahlung √ºber 89,99 ‚Ç¨ wurde am 15. August 2024 verbucht.\n",
        "\"\"\"\n",
        "\n",
        "# PIIranha-Spans abrufen\n",
        "piiranha_spans = get_piiranha_spans(sample_text)\n",
        "spacy_spans = get_spacy_spans(sample_text)\n",
        "regex_spans = get_regex_spans(sample_text)\n",
        "\n",
        "# Ergebnisse ausgeben\n",
        "print(piiranha_spans)\n",
        "print(spacy_spans)\n",
        "print(regex_spans)\n",
        "print(\"Hi\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de382f01",
      "metadata": {
        "id": "de382f01"
      },
      "outputs": [],
      "source": [
        "# üß† Duplikate/√úberschneidungen optional vereinfachen\n",
        "def merge_spans(spans):\n",
        "    return sorted(spans, key=lambda x: x['start'])\n",
        "\n",
        "def resolve_conflicts(spans):\n",
        "    # Sortiere Spans nach Startindex, dann nach L√§nge absteigend (damit √§u√üere zuerst), dann nach Priorit√§t\n",
        "    spans = sorted(spans, key=lambda x: (x[\"start\"], -(x[\"end\"] - x[\"start\"]), -PRIORITY_MAP.get(x.get(\"source\", \"\"), 0)))\n",
        "\n",
        "    resolved = []\n",
        "    occupied = set()\n",
        "\n",
        "    for span in spans:\n",
        "        span_range = set(range(span[\"start\"], span[\"end\"]))\n",
        "        conflict = False\n",
        "\n",
        "        for existing in resolved:\n",
        "            existing_range = set(range(existing[\"start\"], existing[\"end\"]))\n",
        "\n",
        "            # ‚ùå Wenn Spans sich √ºberschneiden\n",
        "            if span_range & existing_range:\n",
        "                # ‚ûï Wenn span vollst√§ndig in existing liegt oder umgekehrt ‚Üí Priorit√§t entscheidet\n",
        "                if span[\"start\"] >= existing[\"start\"] and span[\"end\"] <= existing[\"end\"]:\n",
        "                    if PRIORITY_MAP[span[\"source\"]] > PRIORITY_MAP[existing[\"source\"]]:\n",
        "                        resolved.remove(existing)\n",
        "                        break\n",
        "                    else:\n",
        "                        conflict = True\n",
        "                        break\n",
        "                elif existing[\"start\"] >= span[\"start\"] and existing[\"end\"] <= span[\"end\"]:\n",
        "                    if PRIORITY_MAP[span[\"source\"]] < PRIORITY_MAP[existing[\"source\"]]:\n",
        "                        conflict = True\n",
        "                        break\n",
        "                    else:\n",
        "                        resolved.remove(existing)\n",
        "                        break\n",
        "                else:\n",
        "                    conflict = True\n",
        "                    break\n",
        "\n",
        "        if not conflict:\n",
        "            resolved.append(span)\n",
        "            occupied.update(span_range)\n",
        "\n",
        "    return resolved\n",
        "\n",
        "\n",
        "\n",
        "# üîê Redaktion anwenden\n",
        "def apply_final_redaction(text, spans):\n",
        "    spans = sorted(spans, key=lambda x: x[\"start\"])\n",
        "    redacted = []\n",
        "    last_index = 0\n",
        "\n",
        "    for span in spans:\n",
        "        # Text vor dem Span beibehalten\n",
        "        redacted.append(text[last_index:span[\"start\"]])\n",
        "        # Ersetzung einf√ºgen\n",
        "        redacted.append(f\"[{span['label']}]\")\n",
        "        # Update der Position\n",
        "        last_index = span[\"end\"]\n",
        "\n",
        "    # Rest anh√§ngen\n",
        "    redacted.append(text[last_index:])\n",
        "    return ''.join(redacted)\n",
        "\n",
        "\n",
        "# üß© Hauptfunktion\n",
        "def mask_text_with_all(text):\n",
        "    all_spans = []\n",
        "\n",
        "    # Ergebnisse holen und mit 'source' annotieren\n",
        "    for span in get_regex_spans(text):\n",
        "        span[\"source\"] = \"regex\"\n",
        "        all_spans.append(span)\n",
        "\n",
        "    for span in get_piiranha_spans(text):\n",
        "        span[\"source\"] = \"piiranha\"\n",
        "        all_spans.append(span)\n",
        "\n",
        "    for span in get_spacy_spans(text):\n",
        "        span[\"source\"] = \"spacy\"\n",
        "        all_spans.append(span)\n",
        "\n",
        "    # üîß Konflikte aufl√∂sen\n",
        "    spans = resolve_conflicts(all_spans)\n",
        "\n",
        "    merged = merge_spans(spans)\n",
        "    return apply_final_redaction(text, merged)\n",
        "\n",
        "def mask_text_with_single_component(text, component=\"regex\"):\n",
        "    if component == \"regex\":\n",
        "        all_spans = get_regex_spans(text)\n",
        "    elif component == \"piiranha\":\n",
        "        all_spans = get_piiranha_spans(text)\n",
        "    elif component == \"spacy\":\n",
        "        all_spans = get_spacy_spans(text)\n",
        "    else:\n",
        "        raise ValueError(f\"Unbekannte Komponente: {component}\")\n",
        "\n",
        "    # Optional: Konflikte l√∂sen, falls eine Komponente mehrere Spans mit √úberschneidung liefert\n",
        "    spans = resolve_conflicts(all_spans)\n",
        "    merged = merge_spans(spans)\n",
        "\n",
        "    # Gib nur den maskierten Text zur√ºck ‚Äì analog zur all-Funktion\n",
        "    return apply_final_redaction(text, merged)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "601fabb9",
      "metadata": {
        "id": "601fabb9",
        "outputId": "b6ab037f-ba0f-4ef2-b293-d04258445f3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'start': 39, 'end': 44, 'label': 'ADRESSE'}, {'start': 208, 'end': 232, 'label': 'NAME'}, {'start': 305, 'end': 314, 'label': 'NAME'}, {'start': 369, 'end': 393, 'label': 'NAME'}]\n",
            "[{'start': 49, 'end': 60, 'label': 'ADRESSE'}, {'start': 209, 'end': 232, 'label': 'NAME'}, {'start': 291, 'end': 314, 'label': 'NAME'}, {'start': 370, 'end': 393, 'label': 'ADRESSE'}, {'start': 452, 'end': 460, 'label': 'FIRMA'}]\n",
            "[{'start': 40, 'end': 44, 'label': 'DATUM'}, {'start': 233, 'end': 243, 'label': 'DATUM'}]\n",
            "\n",
            "Sehr geehrte Damen und Herren,\n",
            "Ich habe 2021 das Haus meines verstorbenen\n",
            "Onkels √ºbernommen.\n",
            "Leider wurde damals vers√§umt den Namen im Vertrag zu √§ndern.\n",
            "Ich bitte die Daten im Vertrag entsprechend zu √§ndern.\n",
            "Karl-Friedrich R√∂rricht\n",
            "20.06.1980\n",
            "Die Bankverbindung(Einziehung vom Konto meiner Schwester John R√∂rricht) kann weiter verwendet werden.\n",
            "Mit freundlichen Gr√º√üen\n",
            "Karl-Friedrich R√∂rricht\n",
            "Diese Nachricht wurde von meinem Android Mobiltelefon mit GMX Mail gesendet.\n",
            "\n",
            "Sehr geehrte Damen und Herren,\n",
            "Ich habe [DATUM] das [ADRESSE] verstorbenen\n",
            "Onkels √ºbernommen.\n",
            "Leider wurde damals vers√§umt den Namen im Vertrag zu √§ndern.\n",
            "Ich bitte die Daten im Vertrag entsprechend zu √§ndern.\n",
            "[NAME]\n",
            "[DATUM]\n",
            "Die Bankverbindung(Einziehung vom Konto meiner [NAME]) kann weiter verwendet werden.\n",
            "Mit freundlichen Gr√º√üen\n",
            "[ADRESSE]\n",
            "Diese Nachricht wurde von meinem Android Mobiltelefon mit [FIRMA] gesendet.\n",
            "\n",
            "Sehr geehrte Damen und Herren,\n",
            "Ich habe[ADRESSE] das Haus meines verstorbenen\n",
            "Onkels √ºbernommen.\n",
            "Leider wurde damals vers√§umt den Namen im Vertrag zu √§ndern.\n",
            "Ich bitte die Daten im Vertrag entsprechend zu √§ndern.[NAME]\n",
            "20.06.1980\n",
            "Die Bankverbindung(Einziehung vom Konto meiner Schwester John[NAME]) kann weiter verwendet werden.\n",
            "Mit freundlichen Gr√º√üen[NAME]\n",
            "Diese Nachricht wurde von meinem Android Mobiltelefon mit GMX Mail gesendet.\n",
            "\n",
            "Sehr geehrte Damen und Herren,\n",
            "Ich habe [DATUM] das Haus meines verstorbenen\n",
            "Onkels √ºbernommen.\n",
            "Leider wurde damals vers√§umt den Namen im Vertrag zu √§ndern.\n",
            "Ich bitte die Daten im Vertrag entsprechend zu √§ndern.\n",
            "Karl-Friedrich R√∂rricht\n",
            "[DATUM]\n",
            "Die Bankverbindung(Einziehung vom Konto meiner Schwester John R√∂rricht) kann weiter verwendet werden.\n",
            "Mit freundlichen Gr√º√üen\n",
            "Karl-Friedrich R√∂rricht\n",
            "Diese Nachricht wurde von meinem Android Mobiltelefon mit GMX Mail gesendet.\n",
            "\n",
            "Sehr geehrte Damen und Herren,\n",
            "Ich habe 2021 das [ADRESSE] verstorbenen\n",
            "Onkels √ºbernommen.\n",
            "Leider wurde damals vers√§umt den Namen im Vertrag zu √§ndern.\n",
            "Ich bitte die Daten im Vertrag entsprechend zu √§ndern.\n",
            "[NAME]\n",
            "20.06.1980\n",
            "Die Bankverbindung(Einziehung vom Konto meiner [NAME]) kann weiter verwendet werden.\n",
            "Mit freundlichen Gr√º√üen\n",
            "[ADRESSE]\n",
            "Diese Nachricht wurde von meinem Android Mobiltelefon mit [FIRMA] gesendet.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sample = \"Sehr geehrte Damen und Herren,\\nIch habe 2021 das Haus meines verstorbenen\\nOnkels \\u00fcbernommen.\\nLeider wurde damals vers\\u00e4umt den Namen im Vertrag zu \\u00e4ndern.\\nIch bitte die Daten im Vertrag entsprechend zu \\u00e4ndern.\\nKarl-Friedrich R\\u00f6rricht\\n20.06.1980\\nDie Bankverbindung(Einziehung vom Konto meiner Schwester John R\\u00f6rricht) kann weiter verwendet werden.\\nMit freundlichen Gr\\u00fc\\u00dfen\\nKarl-Friedrich R\\u00f6rricht\\nDiese Nachricht wurde von meinem Android Mobiltelefon mit GMX Mail gesendet.\\n\"\n",
        "\n",
        "print(get_piiranha_spans(sample))\n",
        "print(get_spacy_spans(sample))\n",
        "print(get_regex_spans(sample))\n",
        "print()\n",
        "print(sample)\n",
        "print(mask_text_with_all(sample))\n",
        "print(mask_text_with_single_component(sample, component=\"piiranha\"))\n",
        "print(mask_text_with_single_component(sample, component=\"regex\"))\n",
        "print(mask_text_with_single_component(sample, component=\"spacy\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "27c02379",
      "metadata": {
        "id": "27c02379",
        "outputId": "0171285c-3eb0-436d-9158-e4b006e3ea7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   component             label  precision  recall  f1-score  support\n",
            "25  PIIranha           ADRESSE      0.000   0.000     0.000    427.0\n",
            "0      Regex           ADRESSE      0.000   0.000     0.000    427.0\n",
            "37  combined           ADRESSE      0.000   0.000     0.000    427.0\n",
            "13     spaCy           ADRESSE      0.000   0.000     0.000    427.0\n",
            "26  PIIranha             DATUM      0.000   0.000     0.000    236.0\n",
            "1      Regex             DATUM      0.907   0.822     0.862    236.0\n",
            "38  combined             DATUM      0.907   0.822     0.862    236.0\n",
            "14     spaCy             DATUM      0.000   0.000     0.000    236.0\n",
            "27  PIIranha             FIRMA      0.000   0.000     0.000    140.0\n",
            "2      Regex             FIRMA      0.000   0.000     0.000    140.0\n",
            "39  combined             FIRMA      0.271   0.564     0.367    140.0\n",
            "15     spaCy             FIRMA      0.252   0.564     0.349    140.0\n",
            "28  PIIranha           KONTAKT      0.000   0.000     0.000    336.0\n",
            "4      Regex           KONTAKT      0.000   0.000     0.000    336.0\n",
            "41  combined           KONTAKT      0.000   0.000     0.000    336.0\n",
            "16     spaCy           KONTAKT      0.000   0.000     0.000    336.0\n",
            "29  PIIranha              NAME      0.000   0.000     0.000    479.0\n",
            "5      Regex              NAME      0.000   0.000     0.000    479.0\n",
            "42  combined              NAME      0.000   0.000     0.000    479.0\n",
            "17     spaCy              NAME      0.000   0.000     0.000    479.0\n",
            "31  PIIranha  TECHNISCHE_DATEN      0.000   0.000     0.000    113.0\n",
            "7      Regex  TECHNISCHE_DATEN      0.000   0.000     0.000    113.0\n",
            "44  combined  TECHNISCHE_DATEN      0.000   0.000     0.000    113.0\n",
            "19     spaCy  TECHNISCHE_DATEN      0.000   0.000     0.000    113.0\n",
            "32  PIIranha           VERTRAG      0.000   0.000     0.000    169.0\n",
            "8      Regex           VERTRAG      0.000   0.000     0.000    169.0\n",
            "45  combined           VERTRAG      0.000   0.000     0.000    169.0\n",
            "20     spaCy           VERTRAG      0.000   0.000     0.000    169.0\n",
            "33  PIIranha           ZAHLUNG      0.000   0.000     0.000     90.0\n",
            "9      Regex           ZAHLUNG      1.000   0.311     0.475     90.0\n",
            "46  combined           ZAHLUNG      1.000   0.311     0.475     90.0\n",
            "21     spaCy           ZAHLUNG      0.000   0.000     0.000     90.0\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# üìÇ Testdaten laden\n",
        "with open(\"data_piiranha/test_labels.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "# üéØ Ground Truth in zeichenbasierte Labels umwandeln\n",
        "def extract_true_labels(data):\n",
        "    texts, labels = [], []\n",
        "    for entry in data:\n",
        "        text = entry[\"text\"]\n",
        "        char_labels = [\"O\"] * len(text)\n",
        "        for label in entry[\"labels\"]:\n",
        "            for i in range(label[\"start\"], label[\"end\"]):\n",
        "                char_labels[i] = label[\"label\"]\n",
        "        texts.append(text)\n",
        "        labels.append(char_labels)\n",
        "    return texts, labels\n",
        "\n",
        "# üß© Hilfsfunktion: PII-Spans ‚Üí Zeichenbasierte Labels\n",
        "def spans_to_charlabels(text, spans):\n",
        "    labels = [\"O\"] * len(text)\n",
        "    for span in spans:\n",
        "        for i in range(span[\"start\"], span[\"end\"]):\n",
        "            labels[i] = span[\"label\"]\n",
        "    return labels\n",
        "\n",
        "# üîç Komponenten (diese Funktionen nutzt du aus deinem Erkennungscode)\n",
        "def run_regex_component(text):\n",
        "    return spans_to_charlabels(text, get_regex_spans(text))\n",
        "\n",
        "def run_spacy_component(text):\n",
        "    return spans_to_charlabels(text, get_spacy_spans(text))\n",
        "\n",
        "def run_piiranha_component(text):\n",
        "    return spans_to_charlabels(text, get_piiranha_spans(text))\n",
        "\n",
        "def run_combined_component(text):\n",
        "    all_spans = []\n",
        "    for span in get_regex_spans(text):\n",
        "        span[\"source\"] = \"regex\"\n",
        "        all_spans.append(span)\n",
        "    for span in get_piiranha_spans(text):\n",
        "        span[\"source\"] = \"piiranha\"\n",
        "        all_spans.append(span)\n",
        "    for span in get_spacy_spans(text):\n",
        "        span[\"source\"] = \"spacy\"\n",
        "        all_spans.append(span)\n",
        "\n",
        "    resolved = resolve_conflicts(all_spans)\n",
        "    merged = merge_spans(resolved)\n",
        "    return spans_to_charlabels(text, merged)\n",
        "\n",
        "# üß™ Evaluation pro Komponente\n",
        "def evaluate_component(name, component_fn, texts, y_true):\n",
        "    y_pred = [component_fn(text) for text in texts]\n",
        "    y_true_flat = [label for seq in y_true for label in seq]\n",
        "    y_pred_flat = [label for seq in y_pred for label in seq]\n",
        "    report = classification_report(y_true_flat, y_pred_flat, output_dict=True, zero_division=0)\n",
        "    df = pd.DataFrame(report).transpose()\n",
        "    df[\"component\"] = name\n",
        "    return df\n",
        "\n",
        "# üöÄ Hauptauswertung starten\n",
        "texts, y_true = extract_true_labels(test_data)\n",
        "\n",
        "results = [\n",
        "    evaluate_component(\"Regex\", run_regex_component, texts, y_true),\n",
        "    evaluate_component(\"spaCy\", run_spacy_component, texts, y_true),\n",
        "    evaluate_component(\"PIIranha\", run_piiranha_component, texts, y_true),\n",
        "    evaluate_component(\"combined\", run_combined_component, texts, y_true)\n",
        "]\n",
        "\n",
        "# üìä Ergebnisse kombinieren\n",
        "result_df = pd.concat(results).reset_index().rename(columns={\"index\": \"label\"})\n",
        "\n",
        "# üîç Relevante PII-Kategorien ausw√§hlen\n",
        "relevant_labels = [\"NAME\", \"ADRESSE\", \"FIRMA\", \"DATUM\", \"KONTAKT\", \"VERTRAG\", \"ZAHLUNG\", \"TECHNISCHE_DATEN\"]\n",
        "filtered_df = result_df[result_df[\"label\"].isin(relevant_labels)]\n",
        "\n",
        "# ‚úÖ Finale √úbersicht\n",
        "final_df = filtered_df[[\"component\", \"label\", \"precision\", \"recall\", \"f1-score\", \"support\"]]\n",
        "print(final_df.sort_values([\"label\", \"component\"]).round(3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1aa5a7f0",
      "metadata": {
        "id": "1aa5a7f0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}