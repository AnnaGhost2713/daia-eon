{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-05T21:21:31.932238Z",
     "start_time": "2025-06-05T21:21:31.913025Z"
    }
   },
   "source": [
    "import json\n",
    "import json\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "import evaluate\n",
    "\n",
    "\n",
    "# Pfade anpassen\n",
    "train_path = \"../data/real_focus_zusammengefasst/train_zusammengefasst.json\"\n",
    "dev_path = \"../data/real_focus_zusammengefasst/dev_zusammengefasst.json\"\n",
    "\n",
    "def load_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "train_data = load_json(train_path)\n",
    "dev_data = load_json(dev_path)\n",
    "\n",
    "\n",
    "print(f\"{len(train_data)} Trainingsbeispiele, {len(dev_data)} Validierungsbeispiele\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 Trainingsbeispiele, 24 Validierungsbeispiele\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T21:21:36.525411Z",
     "start_time": "2025-06-05T21:21:35.756407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"iiiorg/piiranha-v1-detect-personal-information\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_and_tag(data):\n",
    "    tokenized = []\n",
    "    for example in data:\n",
    "        text = example[\"text\"]\n",
    "        spans = example[\"labels\"]\n",
    "        encoding = tokenizer(text, return_offsets_mapping=True, truncation=True)\n",
    "        tokens = tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"])\n",
    "        offsets = encoding[\"offset_mapping\"]\n",
    "        ner_tags = []\n",
    "\n",
    "        for (start, end) in offsets:\n",
    "            if start == end:\n",
    "                ner_tags.append(\"O\")\n",
    "                continue\n",
    "            label = \"O\"\n",
    "            for span in spans:\n",
    "                if start >= span[\"start\"] and end <= span[\"end\"]:\n",
    "                    label = span[\"label\"]\n",
    "                    break\n",
    "            ner_tags.append(label)\n",
    "\n",
    "        tokenized.append({\n",
    "            \"tokens\": tokens,\n",
    "            \"labels\": ner_tags\n",
    "        })\n",
    "    return tokenized\n",
    "\n",
    "tokenized_train_raw = tokenize_and_tag(train_data)\n",
    "tokenized_dev_raw = tokenize_and_tag(dev_data)\n",
    "\n",
    "ds_train = Dataset.from_list(tokenized_train_raw)\n",
    "ds_dev = Dataset.from_list(tokenized_dev_raw)\n"
   ],
   "id": "c8306b3fbcdecd1f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T21:21:40.175530Z",
     "start_time": "2025-06-05T21:21:40.140333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unique_labels = sorted(set(lab for x in ds_train[\"labels\"] for lab in x if lab != \"O\"))\n",
    "label2id = {\"O\": 0, **{label: i+1 for i, label in enumerate(unique_labels)}}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "def encode_labels(example):\n",
    "    example[\"labels\"] = [label2id[label] for label in example[\"labels\"]]\n",
    "    return example\n",
    "\n",
    "ds_train = ds_train.map(encode_labels)\n",
    "ds_dev = ds_dev.map(encode_labels)\n"
   ],
   "id": "3611d4eb52ba1bd6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 112/112 [00:00<00:00, 6185.47 examples/s]\n",
      "Map: 100%|██████████| 24/24 [00:00<00:00, 7411.52 examples/s]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T21:21:43.031233Z",
     "start_time": "2025-06-05T21:21:42.947717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], is_split_into_words=True, truncation=True, padding=\"max_length\", max_length=256)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        prev_word_id = None\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_id != prev_word_id:\n",
    "                label_ids.append(label[word_id])\n",
    "            else:\n",
    "                label_ids.append(label[word_id])\n",
    "            prev_word_id = word_id\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_train = ds_train.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_dev = ds_dev.map(tokenize_and_align_labels, batched=True)\n"
   ],
   "id": "5efeb2437974e4d4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 112/112 [00:00<00:00, 3440.75 examples/s]\n",
      "Map: 100%|██████████| 24/24 [00:00<00:00, 3642.60 examples/s]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T21:56:15.244390Z",
     "start_time": "2025-06-05T21:51:05.867325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "# Modell und Tokenizer laden\n",
    "model_name = \"iiiorg/piiranha-v1-detect-personal-information\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Collator und Metrik\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "metric = evaluate.load(\"seqeval\", scheme_type=\"IOB2\")\n",
    "\n",
    "# Metrics-Funktion\n",
    "\n",
    "# Trainingsparameter\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./piiranha-custom-model\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    logging_steps=200,\n",
    "    save_steps=500,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\"\n",
    ")\n",
    "\n",
    "# Trainer definieren\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_dev,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 🔁 Modell trainieren\n",
    "trainer.train()\n",
    "\n",
    "# 🧪 Optional: Evaluation auf Validierungsdaten explizit anstoßen\n",
    "print(\"\\n🔎 Manuelle Evaluation auf Validierungsdaten:\")\n",
    "trainer.evaluate()\n"
   ],
   "id": "f25741c2cc37835c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at iiiorg/piiranha-v1-detect-personal-information and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([18]) in the checkpoint and torch.Size([9]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([18, 768]) in the checkpoint and torch.Size([9, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 04:56, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔎 Manuelle Evaluation auf Validierungsdaten:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 03:57]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.28166326880455017,\n",
       " 'eval_precision': 0.11827956989247312,\n",
       " 'eval_recall': 0.10476190476190476,\n",
       " 'eval_f1': 0.1111111111111111,\n",
       " 'eval_accuracy': 0.9229226361031518,\n",
       " 'eval_runtime': 1.7135,\n",
       " 'eval_samples_per_second': 14.006,\n",
       " 'eval_steps_per_second': 1.751,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T22:13:55.165129Z",
     "start_time": "2025-06-05T22:13:55.149146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(p):\n",
    "    preds, labels = p\n",
    "    preds = np.argmax(preds, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(pred, lab) if l != -100]\n",
    "        for pred, lab in zip(preds, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2label[l] for (p, l) in zip(pred, lab) if l != -100]\n",
    "        for pred, lab in zip(preds, labels)\n",
    "    ]\n",
    "\n",
    "    # Metriken berechnen\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    # ✅ Detaillierte Ergebnisse ausgeben\n",
    "    print(\"\\n📊 Ergebnisse pro Label:\")\n",
    "    for label in results['entities']:\n",
    "        scores = results['entities'][label]\n",
    "        print(f\"{label}: P={scores['precision']:.2%}, R={scores['recall']:.2%}, F1={scores['f1']:.2%}\")\n",
    "\n",
    "    # Ergebnisse zurückgeben (gesamt + je Label)\n",
    "    return {\n",
    "        \"precision\": results[\"overall\"][\"precision\"],\n",
    "        \"recall\": results[\"overall\"][\"recall\"],\n",
    "        \"f1\": results[\"overall\"][\"f1\"],\n",
    "        \"accuracy\": results[\"overall\"][\"accuracy\"],\n",
    "        **{f\"{label}_f1\": results[\"entities\"][label][\"f1\"] for label in results[\"entities\"]}\n",
    "    }\n"
   ],
   "id": "8ba711b4aec45804",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T22:14:08.847373Z",
     "start_time": "2025-06-05T22:14:03.120389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)\n"
   ],
   "id": "78716a0e6939434d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28166326880455017, 'eval_precision': 0.11827956989247312, 'eval_recall': 0.10476190476190476, 'eval_f1': 0.1111111111111111, 'eval_accuracy': 0.9229226361031518, 'eval_runtime': 5.7013, 'eval_samples_per_second': 4.21, 'eval_steps_per_second': 0.526}\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T22:18:04.348282Z",
     "start_time": "2025-06-05T22:18:04.279246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import nbformat\n",
    "\n",
    "# Lade das Notebook\n",
    "notebook_path = Path(\"../data/piiranha_file.ipynb\")\n",
    "with open(notebook_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    notebook_content = f.read()\n",
    "\n",
    "# Parse das Notebook\n",
    "nb = nbformat.reads(notebook_content, as_version=4)\n",
    "\n",
    "# Durchsuche alle Codezellen nach compute_metrics und ersetze sie\n",
    "for cell in nb.cells:\n",
    "    if cell.cell_type == \"code\" and \"def compute_metrics\" in cell.source:\n",
    "        cell.source = '''\n",
    "def compute_metrics(p):\n",
    "    preds, labels = p\n",
    "    preds = np.argmax(preds, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(pred, lab) if l != -100]\n",
    "        for pred, lab in zip(preds, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2label[l] for (p, l) in zip(pred, lab) if l != -100]\n",
    "        for pred, lab in zip(preds, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    print(\"\\\\n📊 Ergebnisse pro Label:\")\n",
    "    for label in results['entities']:\n",
    "        scores = results['entities'][label]\n",
    "        print(f\"{label}: P={scores['precision']:.2%}, R={scores['recall']:.2%}, F1={scores['f1']:.2%}\")\n",
    "\n",
    "    return {\n",
    "        \"precision\": results[\"overall\"][\"precision\"],\n",
    "        \"recall\": results[\"overall\"][\"recall\"],\n",
    "        \"f1\": results[\"overall\"][\"f1\"],\n",
    "        \"accuracy\": results[\"overall\"][\"accuracy\"],\n",
    "        **{f\"{label}_f1\": results[\"entities\"][label][\"f1\"] for label in results[\"entities\"]}\n",
    "    }\n",
    "'''\n",
    "\n",
    "# Speichere das aktualisierte Notebook\n",
    "updated_path = \"/mnt/data/piiranha_file_updated.ipynb\"\n",
    "with open(updated_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    nbformat.write(nb, f)\n",
    "\n",
    "updated_path\n"
   ],
   "id": "ef12c450ac5c96cf",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/piiranha_file.ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[58], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Lade das Notebook\u001B[39;00m\n\u001B[1;32m      5\u001B[0m notebook_path \u001B[38;5;241m=\u001B[39m Path(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data/piiranha_file.ipynb\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnotebook_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m      7\u001B[0m     notebook_content \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Parse das Notebook\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/piranha-env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    319\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    322\u001B[0m     )\n\u001B[0;32m--> 324\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/piiranha_file.ipynb'"
     ]
    }
   ],
   "execution_count": 58
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
