{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-03T13:47:10.338933Z",
     "start_time": "2025-07-03T13:47:10.311574Z"
    }
   },
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Script to split JSON dataset into train/validation/test sets\n",
    "ensuring all labels appear in test set with good representation.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Dict, Tuple, Set\n",
    "\n",
    "def load_json_data(filepath: str) -> List[Dict]:\n",
    "    \"\"\"Load JSON data from file.\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json_data(data: List[Dict], filepath: str) -> None:\n",
    "    \"\"\"Save data to JSON file.\"\"\"\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def get_labels_from_sample(sample: Dict) -> Set[str]:\n",
    "    \"\"\"Extract unique labels from a sample.\"\"\"\n",
    "    return {label['label'] for label in sample.get('labels', [])}\n",
    "\n",
    "def analyze_label_distribution(data: List[Dict]) -> Dict[str, int]:\n",
    "    \"\"\"Analyze label frequency across the dataset.\"\"\"\n",
    "    label_counts = Counter()\n",
    "    for sample in data:\n",
    "        labels = get_labels_from_sample(sample)\n",
    "        label_counts.update(labels)\n",
    "    return dict(label_counts)\n",
    "\n",
    "def get_samples_with_labels(data: List[Dict], target_labels: Set[str]) -> List[int]:\n",
    "    \"\"\"Get indices of samples that contain any of the target labels.\"\"\"\n",
    "    indices = []\n",
    "    for i, sample in enumerate(data):\n",
    "        sample_labels = get_labels_from_sample(sample)\n",
    "        if sample_labels.intersection(target_labels):\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "def stratified_split(data: List[Dict], test_size: int = 50, val_size: int = 30) -> Tuple[List[Dict], List[Dict], List[Dict]]:\n",
    "    \"\"\"\n",
    "    Split data ensuring all labels appear in test set with good representation.\n",
    "\n",
    "    Strategy:\n",
    "    1. Identify all unique labels\n",
    "    2. For rare labels, ensure they appear multiple times in test set\n",
    "    3. Use stratified sampling to maintain label distribution\n",
    "    4. Remaining samples go to train/val\n",
    "    \"\"\"\n",
    "    print(f\"Total samples: {len(data)}\")\n",
    "\n",
    "    # Analyze label distribution\n",
    "    label_counts = analyze_label_distribution(data)\n",
    "    all_labels = set(label_counts.keys())\n",
    "    print(f\"Total unique labels: {len(all_labels)}\")\n",
    "    print(f\"Label distribution: {label_counts}\")\n",
    "\n",
    "    # Find rare labels (appearing in <5% of samples)\n",
    "    rare_threshold = len(data) * 0.05\n",
    "    rare_labels = {label for label, count in label_counts.items() if count < rare_threshold}\n",
    "    print(f\"Rare labels (< {rare_threshold:.1f} samples): {rare_labels}\")\n",
    "\n",
    "    # Create sample-to-labels mapping\n",
    "    sample_labels = [get_labels_from_sample(sample) for sample in data]\n",
    "\n",
    "    # Initialize sets\n",
    "    test_indices = set()\n",
    "    used_indices = set()\n",
    "    labels_in_test = set()\n",
    "\n",
    "    # Step 1: Ensure each label appears at least twice in test set\n",
    "    for label in all_labels:\n",
    "        samples_with_label = [i for i, labels in enumerate(sample_labels)\n",
    "                             if label in labels and i not in used_indices]\n",
    "\n",
    "        if len(samples_with_label) == 0:\n",
    "            print(f\"Warning: Label '{label}' not found in available samples\")\n",
    "            continue\n",
    "\n",
    "        # For rare labels, try to get more samples in test set\n",
    "        target_count = min(3 if label in rare_labels else 2, len(samples_with_label))\n",
    "\n",
    "        # Randomly select samples for this label\n",
    "        selected = random.sample(samples_with_label, target_count)\n",
    "        test_indices.update(selected)\n",
    "        used_indices.update(selected)\n",
    "        labels_in_test.add(label)\n",
    "\n",
    "        print(f\"Added {len(selected)} samples for label '{label}' to test set\")\n",
    "\n",
    "    # Step 2: Fill remaining test set slots with diverse samples\n",
    "    remaining_samples = [i for i in range(len(data)) if i not in used_indices]\n",
    "    remaining_needed = test_size - len(test_indices)\n",
    "\n",
    "    if remaining_needed > 0 and len(remaining_samples) >= remaining_needed:\n",
    "        # Prefer samples with multiple labels for diversity\n",
    "        remaining_samples.sort(key=lambda i: len(sample_labels[i]), reverse=True)\n",
    "        additional_test = remaining_samples[:remaining_needed]\n",
    "        test_indices.update(additional_test)\n",
    "        used_indices.update(additional_test)\n",
    "\n",
    "        print(f\"Added {len(additional_test)} additional samples to test set\")\n",
    "\n",
    "    # Step 3: Split remaining samples into train/val\n",
    "    remaining_samples = [i for i in range(len(data)) if i not in used_indices]\n",
    "    random.shuffle(remaining_samples)\n",
    "\n",
    "    val_indices = set(remaining_samples[:val_size])\n",
    "    train_indices = set(remaining_samples[val_size:])\n",
    "\n",
    "    # Create final datasets\n",
    "    test_data = [data[i] for i in test_indices]\n",
    "    val_data = [data[i] for i in val_indices]\n",
    "    train_data = [data[i] for i in train_indices]\n",
    "\n",
    "    # Verify all labels are in test set\n",
    "    test_labels = set()\n",
    "    for sample in test_data:\n",
    "        test_labels.update(get_labels_from_sample(sample))\n",
    "\n",
    "    missing_labels = all_labels - test_labels\n",
    "    if missing_labels:\n",
    "        print(f\"Warning: Labels missing from test set: {missing_labels}\")\n",
    "    else:\n",
    "        print(\"✓ All labels are present in test set\")\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def print_split_statistics(train_data: List[Dict], val_data: List[Dict], test_data: List[Dict]) -> None:\n",
    "    \"\"\"Print statistics about the data split.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DATASET SPLIT STATISTICS\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    datasets = [\n",
    "        (\"Training\", train_data),\n",
    "        (\"Validation\", val_data),\n",
    "        (\"Test\", test_data)\n",
    "    ]\n",
    "\n",
    "    for name, data in datasets:\n",
    "        print(f\"\\n{name} Set:\")\n",
    "        print(f\"  Samples: {len(data)}\")\n",
    "\n",
    "        # Count labels\n",
    "        label_counts = analyze_label_distribution(data)\n",
    "        print(f\"  Unique labels: {len(label_counts)}\")\n",
    "        print(f\"  Total label instances: {sum(label_counts.values())}\")\n",
    "\n",
    "        # Show label distribution\n",
    "        sorted_labels = sorted(label_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        print(f\"  Label distribution: {dict(sorted_labels)}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute the dataset split.\"\"\"\n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(42)\n",
    "\n",
    "    # Define paths\n",
    "    input_path = \"./original_with_spans.json\"\n",
    "    output_dir = \"./granular_dataset_split\"\n",
    "\n",
    "    # Load data\n",
    "    print(\"Loading data...\")\n",
    "    try:\n",
    "        data = load_json_data(input_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find input file at {input_path}\")\n",
    "        return\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON in file {input_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loaded {len(data)} samples\")\n",
    "\n",
    "    # Split data\n",
    "    print(\"\\nSplitting data...\")\n",
    "    train_data, val_data, test_data = stratified_split(data, test_size=50, val_size=30)\n",
    "\n",
    "    # Save split datasets\n",
    "    print(f\"\\nSaving datasets to {output_dir}...\")\n",
    "    save_json_data(train_data, os.path.join(output_dir, \"train.json\"))\n",
    "    save_json_data(val_data, os.path.join(output_dir, \"validation.json\"))\n",
    "    save_json_data(test_data, os.path.join(output_dir, \"test.json\"))\n",
    "\n",
    "    # Print statistics\n",
    "    print_split_statistics(train_data, val_data, test_data)\n",
    "\n",
    "    print(f\"\\n✓ Dataset split completed successfully!\")\n",
    "    print(f\"Files saved in: {output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded 160 samples\n",
      "\n",
      "Splitting data...\n",
      "Total samples: 160\n",
      "Total unique labels: 21\n",
      "Label distribution: {'ZAHLUNG': 22, 'GESENDET_MIT': 25, 'LINK': 7, 'WOHNORT': 58, 'HAUSNUMMER': 57, 'VORNAME': 145, 'NACHNAME': 153, 'POSTLEITZAHL': 58, 'VERTRAGSNUMMER': 63, 'STRASSE': 59, 'TITEL': 13, 'DATUM': 53, 'IBAN': 6, 'ZÄHLERNUMMER': 36, 'TELEFONNUMMER': 33, 'ZÄHLERSTAND': 10, 'FIRMA': 19, 'FAX': 5, 'BANK': 3, 'BIC': 1, 'EMAIL': 13}\n",
      "Rare labels (< 8.0 samples): {'BANK', 'BIC', 'LINK', 'IBAN', 'FAX'}\n",
      "Added 2 samples for label 'ZAHLUNG' to test set\n",
      "Added 3 samples for label 'LINK' to test set\n",
      "Added 2 samples for label 'TELEFONNUMMER' to test set\n",
      "Added 2 samples for label 'VERTRAGSNUMMER' to test set\n",
      "Added 2 samples for label 'STRASSE' to test set\n",
      "Added 2 samples for label 'WOHNORT' to test set\n",
      "Added 3 samples for label 'BANK' to test set\n",
      "Warning: Label 'BIC' not found in available samples\n",
      "Added 2 samples for label 'DATUM' to test set\n",
      "Added 2 samples for label 'EMAIL' to test set\n",
      "Added 2 samples for label 'GESENDET_MIT' to test set\n",
      "Added 2 samples for label 'ZÄHLERSTAND' to test set\n",
      "Added 2 samples for label 'ZÄHLERNUMMER' to test set\n",
      "Added 2 samples for label 'HAUSNUMMER' to test set\n",
      "Added 2 samples for label 'VORNAME' to test set\n",
      "Added 2 samples for label 'FIRMA' to test set\n",
      "Added 2 samples for label 'NACHNAME' to test set\n",
      "Added 2 samples for label 'TITEL' to test set\n",
      "Added 1 samples for label 'IBAN' to test set\n",
      "Added 2 samples for label 'POSTLEITZAHL' to test set\n",
      "Added 3 samples for label 'FAX' to test set\n",
      "Added 8 additional samples to test set\n",
      "✓ All labels are present in test set\n",
      "\n",
      "Saving datasets to ./granular_dataset_split...\n",
      "\n",
      "==================================================\n",
      "DATASET SPLIT STATISTICS\n",
      "==================================================\n",
      "\n",
      "Training Set:\n",
      "  Samples: 80\n",
      "  Unique labels: 17\n",
      "  Total label instances: 346\n",
      "  Label distribution: {'NACHNAME': 76, 'VORNAME': 70, 'VERTRAGSNUMMER': 32, 'DATUM': 26, 'WOHNORT': 21, 'POSTLEITZAHL': 21, 'STRASSE': 21, 'HAUSNUMMER': 20, 'GESENDET_MIT': 13, 'TELEFONNUMMER': 13, 'ZÄHLERNUMMER': 11, 'ZAHLUNG': 10, 'TITEL': 4, 'EMAIL': 3, 'FIRMA': 3, 'LINK': 1, 'FAX': 1}\n",
      "\n",
      "Validation Set:\n",
      "  Samples: 30\n",
      "  Unique labels: 15\n",
      "  Total label instances: 137\n",
      "  Label distribution: {'NACHNAME': 30, 'VORNAME': 29, 'VERTRAGSNUMMER': 11, 'WOHNORT': 10, 'HAUSNUMMER': 10, 'POSTLEITZAHL': 10, 'STRASSE': 10, 'ZÄHLERNUMMER': 8, 'DATUM': 7, 'TELEFONNUMMER': 3, 'ZÄHLERSTAND': 3, 'GESENDET_MIT': 3, 'TITEL': 1, 'ZAHLUNG': 1, 'EMAIL': 1}\n",
      "\n",
      "Test Set:\n",
      "  Samples: 50\n",
      "  Unique labels: 21\n",
      "  Total label instances: 356\n",
      "  Label distribution: {'NACHNAME': 47, 'VORNAME': 46, 'STRASSE': 28, 'WOHNORT': 27, 'HAUSNUMMER': 27, 'POSTLEITZAHL': 27, 'DATUM': 20, 'VERTRAGSNUMMER': 20, 'ZÄHLERNUMMER': 17, 'TELEFONNUMMER': 17, 'FIRMA': 16, 'ZAHLUNG': 11, 'GESENDET_MIT': 9, 'EMAIL': 9, 'TITEL': 8, 'ZÄHLERSTAND': 7, 'LINK': 6, 'IBAN': 6, 'FAX': 4, 'BANK': 3, 'BIC': 1}\n",
      "\n",
      "✓ Dataset split completed successfully!\n",
      "Files saved in: ./granular_dataset_split\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
