{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### üìí Jupyter Notebook zum Training eines benutzerdefinierten spaCy-Modells\n",
    "\n",
    "# üß© Schritt 1: Imports und Setup\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training.example import Example\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# üìÅ Schritt 2: Lade und konvertiere deine Trainingsdaten aus JSON\n",
    "\n",
    "def load_data_from_json(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw_data = json.load(f)\n",
    "\n",
    "    # Falls es eine Liste von Beispielen ist, bleibe bei Liste\n",
    "    if isinstance(raw_data, dict):\n",
    "        raw_data = [raw_data]\n",
    "\n",
    "    TRAIN_DATA = []\n",
    "    for entry in raw_data:\n",
    "        text = entry[\"text\"]\n",
    "        entities = [(label[\"start\"], label[\"end\"], label[\"label\"]) for label in entry[\"labels\"]]\n",
    "        TRAIN_DATA.append((text, {\"entities\": entities}))\n",
    "    return TRAIN_DATA\n",
    "\n",
    "train_data = load_data_from_json(\"templates_with_spans.json\")\n",
    "print(f\"Lade {len(train_data)} Trainingsbeispiele.\")\n",
    "\n",
    "# üîß Schritt 3: Starte mit dem mittleren deutschen spaCy-Basismodell\n",
    "base_model = \"de_core_news_md\"\n",
    "nlp = spacy.load(base_model)\n",
    "\n",
    "# F√ºge ggf. 'ner'-Komponente hinzu\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe(\"ner\", last=True)\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "# Alle Labels hinzuf√ºgen\n",
    "for _, annotations in train_data:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "# üèãÔ∏è Schritt 4: Training vorbereiten\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.resume_training()\n",
    "\n",
    "    # üß† Schritt 5: Trainieren\n",
    "    n_iter = 20\n",
    "    for i in range(n_iter):\n",
    "        random.shuffle(train_data)\n",
    "        losses = {}\n",
    "        for text, annotations in train_data:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "            nlp.update([example], drop=0.35, losses=losses)\n",
    "        print(f\"Iteration {i+1}/{n_iter}, Losses: {losses}\")\n",
    "\n",
    "# üíæ Schritt 6: Speichern des Modells\n",
    "output_dir = Path(\"custom_spacy_model_new\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "nlp.to_disk(output_dir)\n",
    "print(f\"‚úÖ Modell gespeichert unter {output_dir.resolve()}\")\n",
    "\n",
    "# üîç Schritt 7: Testen des Modells\n",
    "nlp2 = spacy.load(output_dir)\n",
    "doc = nlp2(\"Hallo Herr Jacob Mangold, wie kann ich Ihnen helfen?\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
