{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AnnaGhost2713/daia-eon.git\n",
        "%cd daia-eon/notebooks"
      ],
      "metadata": {
        "id": "MtFHCXEuP767",
        "outputId": "9b893594-0d98-4d62-ab5e-a3d1e01bd8b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "MtFHCXEuP767",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'daia-eon' already exists and is not an empty directory.\n",
            "/content/daia-eon/notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pathlib\n",
        "print(\"cwd:\", os.getcwd())\n",
        "print(\"Contents:\", os.listdir())\n",
        "print(\"data/ exists?\", os.path.isdir(\"data\"))\n",
        "print(\"  Inside granular:\", os.listdir(\"data/golden_dataset_anonymized_granular\")[:5])"
      ],
      "metadata": {
        "id": "EI24dmuCQQEU",
        "outputId": "e69f7dc2-2f7f-4c4b-ec56-7edb55fe045d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EI24dmuCQQEU",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cwd: /content/daia-eon/notebooks\n",
            "Contents: ['TESTING.ipynb', '02_piiranha_anonymization.ipynb', 'Gazetteer', 'Creating_synthetic_data.ipynb', 'generate_synthetic_emails.ipynb', 'email_anonymizer.ipynb', 'test_file.ipynb', 'anonymized_emails.txt', 'trains_piranha.ipynb', '01_a_anonymize_gran.ipynb', 'data', 'piranha_model_finetuning.py', '02_paraphrasing.ipynb', '01_load_data.ipynb', 'evaluate_finetuned_model.py', '01_b_make_json.ipynb', 'jsonl_to_spacy.ipynb', '.keep', 'separating_data.ipynb', 'piranha_finetuning_preparation.ipynb', 'generate_piranha_training_data.ipynb']\n",
            "data/ exists? True\n",
            "  Inside granular: ['114.txt', '107.txt', '58.txt', '47.txt', '21.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f2182322-c541-4994-bdfe-365eb278a5c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2182322-c541-4994-bdfe-365eb278a5c3",
        "outputId": "6013d337-1d70-4345-8e5d-9ac62ae389ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📄 114.txt (orig):\n",
            "Kunde: \t\t\t<<FIRMA>>\n",
            "Verbrauchsstelle:\t<<STRASSE>> <<HAUSNUMMER>>\n",
            "Zähler:\t\t\t<<ZÄHLERNUMMER>>\n",
            "Vertragsnummer: <<VERTRAGSNUMMER>>\n",
            "Sehr geehrte Damen und Herren,\n",
            "wir bedanken uns für Ihre Abschlagsanpassung gemäß Ihres Schreibens vom <<DATUM>>, \n",
            "auch wenn Ihr Schreiben auf unsere eingelegten Widersprüche nicht eingegangen ist.\n",
            "Der guten Ordnung halber verweisen wir erneut zu Ihrer im <<DATUM>> angekündigten Preiserhöhung auf unseren Widerspruch vom <<DATUM>>, den wir nach wie vor aus dargelegtem Grund aufrecht erhalten. \n",
            "Mit freundlichen Grüßen\n",
            "<<TITEL>> <<VORNAME>> <<NACHNAME>>\n",
            "- Hausverwaltung -\n",
            "\n",
            "\n",
            "✏️ paraphrase:\n",
            "Sehr geehrte Damen und Herren, wir bedanken uns für Ihre Abschlagsanpassung gemäß Ihres Schreibens vom <<DATUM>>, auch wenn Ihr Schreiben auf unsere eingelegten Widersprüche nicht eingegangen ist.\n",
            "————————————————————————————————————————————————————————————\n",
            "\n",
            "📄 107.txt (orig):\n",
            "Sehr geehrte Damen und Herren,\n",
            "ich möchte Ihnen auf diesem Weg schon jetzt ein Foto eines Schreiben senden, welches Ihnen ab morgen noch über den Postweg zugestellt wird. Bezüglich der Schlussrechnung des Vertrags <<ZÄHLERNUMMER>> bitte ich um dringende Beachtung.\n",
            "Mit freundlichen Grüßen\n",
            "<<VORNAME>> <<NACHNAME>>\n",
            "\n",
            "\n",
            "✏️ paraphrase:\n",
            "Sehr geehrte Damen und Herren, ich möchte Ihnen auf diesem Weg schon jetzt ein Foto eines Schreiben senden, welches Ihnen ab morgen noch über den Postweg zugestellt wird. Bezüglich der Schlussrechnung des Vertrags <<ZÄHLERNUMMER>> bitte um dringende Beachtung.\n",
            "————————————————————————————————————————————————————————————\n",
            "\n",
            "📄 58.txt (orig):\n",
            "Sehr geehrte Damen und Herren,\n",
            "im Auftrag meines Sohnes <<VORNAME>> <<NACHNAME>> bitte ich um die Erklärung des Postens Soforthilfe Dezember. Ich hatte bereits einige Male angerufen mit der Bitte, mir den Betrag aufzuschlüsseln. Leider konnten mir Ihre Mitarbeiter nur die Berechnungsgrundlagen nennen, aber nicht die einzelnen Faktoren (Beträge). Laut Verbraucherzentrale kann man sich den Betrag ausrechnen lassen. Daraufhin ergab sich eine Erstattung von <<ZAHLUNG>> statt <<ZAHLUNG>>.\n",
            "Mit freundlichen Grüßen\n",
            "<<VORNAME>> <<NACHNAME>>\n",
            "i.A. <<VORNAME>> <<NACHNAME>>\n",
            "\n",
            "\n",
            "✏️ paraphrase:\n",
            "Sehr geehrte Damen und Herren, im Auftrag meines Sohnes <<VORNAME>> <<NACHNAME>> bitte ich um die Erklärung des Postens Soforthilfe Dezember.\n",
            "————————————————————————————————————————————————————————————\n"
          ]
        }
      ],
      "source": [
        "#!pip install -q transformers sentencepiece tqdm\n",
        "\n",
        "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "# from tqdm.auto import tqdm\n",
        "# import pathlib, re\n",
        "\n",
        "# Load model on GPU\n",
        "MODEL_ID   = \"milyiyo/paraphraser-german-mt5-small\"\n",
        "tokenizer  = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "model      = AutoModelForSeq2SeqLM.from_pretrained(MODEL_ID).to(\"cuda\")\n",
        "paraphraser= pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer,\n",
        "                      device=0, do_sample=True, temperature=0.9, top_p=0.95, max_length=512)\n",
        "\n",
        "# Grab first 3 templates\n",
        "SRC_DIR    = pathlib.Path(\"data/golden_dataset_anonymized_granular\")\n",
        "examples   = list(SRC_DIR.glob(\"*.txt\"))[:3]\n",
        "\n",
        "for p in examples:\n",
        "    text = p.read_text()\n",
        "    print(f\"\\n📄 {p.name} (orig):\\n{text}\\n\")\n",
        "    out = paraphraser(\"paraphrase: \" + text, num_return_sequences=1)[0][\"generated_text\"]\n",
        "    print(f\"✏️ paraphrase:\\n{out}\\n{'—'*60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jVvJHpkEP9OK"
      },
      "id": "jVvJHpkEP9OK",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}