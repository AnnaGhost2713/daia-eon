{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2182322-c541-4994-bdfe-365eb278a5c3",
      "metadata": {
        "id": "f2182322-c541-4994-bdfe-365eb278a5c3"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers sentencepiece tqdm\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "from tqdm.auto import tqdm\n",
        "import pathlib, re\n",
        "\n",
        "# Load model on GPU\n",
        "MODEL_ID   = \"milyiyo/paraphraser-german-mt5-small\"\n",
        "tokenizer  = AutoTokenizer.from_pretrained(MODEL_ID)\n",
        "model      = AutoModelForSeq2SeqLM.from_pretrained(MODEL_ID).to(\"cuda\")\n",
        "paraphraser= pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer,\n",
        "                      device=0, do_sample=True, temperature=0.9, top_p=0.95, max_length=512)\n",
        "\n",
        "# Grab first 3 templates\n",
        "SRC_DIR    = pathlib.Path(\"data/golden_dataset_anonymized_granular\")\n",
        "examples   = list(SRC_DIR.glob(\"*.txt\"))[:3]\n",
        "\n",
        "for p in examples:\n",
        "    text = p.read_text()\n",
        "    print(f\"\\nüìÑ {p.name} (orig):\\n{text}\\n\")\n",
        "    out = paraphraser(\"paraphrase: \" + text, num_return_sequences=1)[0][\"generated_text\"]\n",
        "    print(f\"‚úèÔ∏è paraphrase:\\n{out}\\n{'‚Äî'*60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L17ZVbCIO4nh"
      },
      "id": "L17ZVbCIO4nh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}