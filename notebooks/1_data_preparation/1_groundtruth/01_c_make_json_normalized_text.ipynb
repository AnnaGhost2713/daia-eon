{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "863f12b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Wrote 160 records to ..\\..\\..\\data\\original\\golden_dataset_with_spans_norm.json\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import unicodedata\n",
    "\n",
    "# ── Normalisierung ───────────────────────────────\n",
    "def normalize(text):\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    text = re.sub(r'[\\u200b\\u2028\\u2029\\ufeff]', '', text)\n",
    "    text = text.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "    return text\n",
    "\n",
    "# ── Überlappende Labels filtern ──────────────────\n",
    "def remove_exactly_nested_labels(labels, text):\n",
    "    labels = sorted(labels, key=lambda x: (x[\"end\"] - x[\"start\"]), reverse=True)\n",
    "    filtered = []\n",
    "    for current in labels:\n",
    "        current_span = text[current[\"start\"]:current[\"end\"]]\n",
    "        overlap = False\n",
    "        for other in filtered:\n",
    "            if (\n",
    "                other[\"start\"] <= current[\"start\"]\n",
    "                and other[\"end\"] >= current[\"end\"]\n",
    "                and text[other[\"start\"]:other[\"end\"]] == current_span\n",
    "            ):\n",
    "                overlap = True\n",
    "                break\n",
    "        if not overlap:\n",
    "            filtered.append(current)\n",
    "    return sorted(filtered, key=lambda x: x[\"start\"])\n",
    "\n",
    "# ── Placeholder-Mapping ───────────────────────────\n",
    "PLACEHOLDERS = {\n",
    "    \"TITEL\":         [\"TITEL\"],\n",
    "    \"VORNAME\":       [\"VORNAME\"],\n",
    "    \"NACHNAME\":      [\"NACHNAME\"],\n",
    "    \"FIRMA\":         [\"FIRMA\"],\n",
    "    \"TELEFONNUMMER\": [\"TELEFONNUMMER\"],\n",
    "    \"EMAIL\":         [\"EMAIL\"],\n",
    "    \"FAX\":           [\"FAX\"],\n",
    "    \"STRASSE\":       [\"STRASSE\"],\n",
    "    \"HAUSNUMMER\":    [\"HAUSNUMMER\"],\n",
    "    \"POSTLEITZAHL\":  [\"POSTLEITZAHL\",\"PLZ\",\"ZIP\"],\n",
    "    \"WOHNORT\":       [\"WOHNORT\",\"ORT\",\"CITY\"],\n",
    "    \"ZÄHLERNUMMER\":  [\"ZÄHLERNUMMER\",\"METER_ID\"],\n",
    "    \"ZÄHLERSTAND\":   [\"ZÄHLERSTAND\",\"METER_READING\"],\n",
    "    \"VERTRAGSNUMMER\":[\"VERTRAGSNUMMER\",\"ANGEBOTSNUMMER\",\"KUNDENNUMMER\", \"RECHNUNGSNUMMER\"],\n",
    "    \"ZAHLUNG\":       [\"BETRAG\",\"ZAHLUNG\",\"AMOUNT\"],\n",
    "    \"BANK\":          [\"BANK\"],\n",
    "    \"IBAN\":          [\"IBAN\"],\n",
    "    \"BIC\":           [\"BIC\"],\n",
    "    \"DATUM\":         [\"DATUM\",\"DATE\"],\n",
    "    \"GESENDET_MIT\":  [\"GESENDET_MIT\"],\n",
    "    \"LINK\":          [\"LINK\"],\n",
    "}\n",
    "\n",
    "SENSITIVE_TAGS = {\"HAUSNUMMER\", \"POSTLEITZAHL\", \"ZAHLUNG\"}\n",
    "\n",
    "def map_col(col: str) -> str|None:\n",
    "    up = col.upper()\n",
    "    for tag, keys in PLACEHOLDERS.items():\n",
    "        if any(k in up for k in keys):\n",
    "            return f\"<<{tag}>>\"\n",
    "    return None\n",
    "\n",
    "def extract_repls(row: pd.Series):\n",
    "    repl = []\n",
    "    for col, val in row.items():\n",
    "        if pd.isna(val): continue\n",
    "        ph = map_col(col)\n",
    "        if not ph: continue\n",
    "        lit = str(val).strip()\n",
    "        if lit:\n",
    "            repl.append((lit, ph))\n",
    "    return sorted(repl, key=lambda x: len(x[0]), reverse=True)\n",
    "\n",
    "# ── Pfade ─────────────────────────────────────────\n",
    "META      = Path(\"../../../data/excel_manual_labeling/Daia_Manual_Labelling_granular.xlsx\")\n",
    "RAW_DIR   = Path(\"../../../data/original/golden_dataset_original\")\n",
    "JSON_OUT  = Path(\"../../../data/original/golden_dataset_with_spans_norm.json\")\n",
    "\n",
    "df = pd.read_excel(META, dtype=str)\n",
    "tag_re = re.compile(r\"<<([^>]+)>>\")\n",
    "\n",
    "output = []\n",
    "\n",
    "# ── Verarbeitung pro Zeile ─────────────────────────\n",
    "for _, row in df.iterrows():\n",
    "    fname     = row[\"TextFile\"]\n",
    "    orig_text = (RAW_DIR/fname).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    norm_text = normalize(orig_text)\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for literal, placeholder in extract_repls(row):\n",
    "        tag = tag_re.match(placeholder).group(1)\n",
    "        norm_lit = re.escape(normalize(literal))\n",
    "\n",
    "        # Wortgrenzen bei sensiblen Werten\n",
    "        if tag in SENSITIVE_TAGS or literal.isdigit():\n",
    "            pattern = rf'\\b{norm_lit}\\b'\n",
    "        else:\n",
    "            pattern = norm_lit\n",
    "\n",
    "        # Suche im normalisierten Originaltext\n",
    "        for m in re.finditer(pattern, norm_text, flags=re.IGNORECASE):\n",
    "            match_norm = m.group()\n",
    "            # suche das exakte Stück im Originaltext, ab Position m.start()\n",
    "            match_orig = orig_text[m.start():m.start()+len(match_norm)]\n",
    "            start = orig_text.find(match_orig, m.start())\n",
    "            if start != -1:\n",
    "                labels.append({\n",
    "                    \"start\": start,\n",
    "                    \"end\":   start + len(match_orig),\n",
    "                    \"label\": tag\n",
    "                })\n",
    "            else:\n",
    "                print(f\"⚠️ Konnte '{match_norm}' nicht im Originaltext finden (Datei: {fname})\")\n",
    "\n",
    "    labels = remove_exactly_nested_labels(labels, orig_text)\n",
    "\n",
    "    output.append({\n",
    "        \"file\":   fname,\n",
    "        \"text\":   orig_text,\n",
    "        \"labels\": labels\n",
    "    })\n",
    "\n",
    "# ── Export ─────────────────────────────────────────\n",
    "JSON_OUT.write_text(json.dumps(output, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(f\"✓ Wrote {len(output)} records to {JSON_OUT}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
