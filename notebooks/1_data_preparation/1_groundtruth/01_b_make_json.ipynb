{
 "cells": [
  {
   "cell_type": "code",
   "id": "2295f658-4bda-4fb1-b6a2-18aaa45ca2e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:11:37.750385Z",
     "start_time": "2025-07-13T13:11:37.743898Z"
    }
   },
   "source": [
    "%cd /Users/annama/Documents/Master/SS 25/Data Analytics in Applications/Code/daia-eon/daia-eon-1/notebooks\n",
    "\n",
    "import pandas as pd, re, random\n",
    "from pathlib import Path\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Users/annama/Documents/Master/SS 25/Data Analytics in Applications/Code/daia-eon/daia-eon-1/notebooks'\n",
      "/Users/timonmartens/Library/CloudStorage/OneDrive-Persönlich/Desktop/Veranstaltungen/Data Analytics in Applications/daia-eon/notebooks/1_data_preparation/1_groundtruth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/piranha-env/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: This is now an optional IPython functionality, using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "28b6b564de8b213f"
  },
  {
   "cell_type": "markdown",
   "id": "ed039fbb-0be3-44ea-9cf9-940ac69f1e50",
   "metadata": {},
   "source": [
    "import re, json\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4fb2c1-69ec-4657-8a51-64651a63613b",
   "metadata": {},
   "source": [
    "# Finegrained placeholder map\n",
    "PLACEHOLDERS = {\n",
    "    \"VORNAME\": {\"VORNAME\"},\n",
    "    \"NACHNAME\": {\"NACHNAME\"},\n",
    "    \"FIRMA\": {\"FIRMA\"},\n",
    "    \"TELEFONNUMMER\": {\"TELEFONNUMMER\"},\n",
    "    \"EMAIL\": {\"EMAIL\"},\n",
    "    \"FAX\": {\"FAX\"},\n",
    "    \"STRASSE\": {\"STRASSE\"},\n",
    "    \"HAUSNUMMER\": {\"HAUSNUMMER\"},\n",
    "    \"POSTLEITZAHL\": {\"POSTLEITZAHL\", \"PLZ\",\"ZIP\"},\n",
    "    \"WOHNORT\": {\"WOHNORT\", \"ORT\",\"CITY\"},\n",
    "    \"ZÄHLERNUMMER\": {\"ZÄHLERNUMMER\", \"METER_ID\"},\n",
    "    \"ZÄHLERSTAND\": {\"ZÄHLERSTAND\", \"METER_READING\"},\n",
    "    \"VERTRAGSNUMMER\": {\"VERTRAGSNUMMER\", \"ANGEBOTSNUMMER\", \"KUNDENNUMMER\"},\n",
    "    \"ZAHLUNG\": {\"BETRAG\",\"ZAHLUNG\",\"AMOUNT\"},\n",
    "    \"BANK\": {\"BANK\"},\n",
    "    \"IBAN\": {\"IBAN\"},\n",
    "    \"BIC\": {\"BIC\"},\n",
    "    \"DATUM\": {\"DATUM\",\"DATE\"},\n",
    "    \"TITEL\": {\"TITEL\"},\n",
    "    \"GESENDET_MIT\": {\"GESENDET_MIT\"},\n",
    "    \"LINK\": {\"LINK\"},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d076c2c3-e085-49c2-9311-2bd12e6c10f8",
   "metadata": {},
   "source": [
    "def map_col(col: str) -> str|None:\n",
    "    up = col.upper()\n",
    "    for tag, keys in PLACEHOLDERS.items():\n",
    "        if any(k in up for k in keys):\n",
    "            return f\"<<{tag}>>\"\n",
    "    return None\n",
    "\n",
    "def extract_repls(row: pd.Series):\n",
    "    repl = []\n",
    "    for col, val in row.items():\n",
    "        if pd.isna(val): continue\n",
    "        ph = map_col(col)\n",
    "        if not ph:    continue\n",
    "        literal = str(val).strip()\n",
    "        if literal:\n",
    "            repl.append((re.escape(literal), ph))\n",
    "    return sorted(repl, key=lambda x: len(x[0]), reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "036f449c-6adc-4ca3-b490-a1b352849a49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:11:37.826884Z",
     "start_time": "2025-07-13T13:11:37.769530Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "\n",
    "META       = Path(\"../../../data/excel_manual_labeling/Daia_Manual_Labelling_granular.xlsx\")\n",
    "RAW_DIR    = Path(\"../../../data/original/golden_dataset_original\")\n",
    "JSON_OUT   = Path(\"../../../data/original/golden_dataset_with_spans.json\")\n",
    "\n",
    "meta    = pd.read_excel(META, dtype=str)\n",
    "records = []\n",
    "tag_re  = re.compile(r\"<<([^>]+)>>\")  # capture inside the chevrons\n",
    "\n",
    "for _, row in meta.iterrows():\n",
    "    fn   = row[\"TextFile\"]\n",
    "    path = RAW_DIR/fn\n",
    "    if not path.exists(): \n",
    "        print(\"⚠️ Missing\", fn)\n",
    "        continue\n",
    "\n",
    "    text   = path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    labels = []\n",
    "\n",
    "    # for each literal→<<TAG>> pairing, find its spans in the original text\n",
    "    for pattern, placeholder in extract_repls(row):\n",
    "        tag = tag_re.match(placeholder).group(1)  # e.g. \"VORNAME\"\n",
    "        for m in re.finditer(pattern, text, flags=re.IGNORECASE):\n",
    "            labels.append({\n",
    "                \"start\": m.start(),\n",
    "                \"end\":   m.end(),\n",
    "                \"label\": tag\n",
    "            })\n",
    "\n",
    "    records.append({\n",
    "        \"file\":   fn,\n",
    "        \"text\":   text,\n",
    "        \"labels\": labels\n",
    "    })\n",
    "\n",
    "JSON_OUT.write_text(json.dumps(records, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(f\"✓ Wrote {len(records)} records to {JSON_OUT}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Wrote 160 records to ../../../data/original/golden_dataset_with_spans.json\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "836db1e5-8422-4e42-a825-a32da077bab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:11:37.890351Z",
     "start_time": "2025-07-13T13:11:37.839095Z"
    }
   },
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ── 0) Assume you already have these from your TXT script ─────────────\n",
    "PLACEHOLDERS = {\n",
    "    \"TITEL\":         [\"TITEL\"],\n",
    "    \"VORNAME\":       [\"VORNAME\"],\n",
    "    \"NACHNAME\":      [\"NACHNAME\"],\n",
    "    \"FIRMA\":         [\"FIRMA\"],\n",
    "    \"TELEFONNUMMER\": [\"TELEFONNUMMER\"],\n",
    "    \"EMAIL\":         [\"EMAIL\"],\n",
    "    \"FAX\":           [\"FAX\"],\n",
    "    \"STRASSE\":       [\"STRASSE\"],\n",
    "    \"HAUSNUMMER\":    [\"HAUSNUMMER\"],\n",
    "    \"POSTLEITZAHL\":  [\"POSTLEITZAHL\",\"PLZ\",\"ZIP\"],\n",
    "    \"WOHNORT\":       [\"WOHNORT\",\"ORT\",\"CITY\"],\n",
    "    \"ZÄHLERNUMMER\":  [\"ZÄHLERNUMMER\",\"METER_ID\"],\n",
    "    \"ZÄHLERSTAND\":   [\"ZÄHLERSTAND\",\"METER_READING\"],\n",
    "    \"VERTRAGSNUMMER\":[\"VERTRAGSNUMMER\",\"ANGEBOTSNUMMER\",\"KUNDENNUMMER\", \"RECHNUNGSNUMMER\"],\n",
    "    \"ZAHLUNG\":       [\"BETRAG\",\"ZAHLUNG\",\"AMOUNT\"],\n",
    "    \"BANK\":          [\"BANK\"],\n",
    "    \"IBAN\":          [\"IBAN\"],\n",
    "    \"BIC\":           [\"BIC\"],\n",
    "    \"DATUM\":         [\"DATUM\",\"DATE\"],\n",
    "    \"GESENDET_MIT\":  [\"GESENDET_MIT\"],\n",
    "    \"LINK\":          [\"LINK\"],\n",
    "}\n",
    "\n",
    "def map_col(col: str) -> str|None:\n",
    "    up = col.upper()\n",
    "    for tag, keys in PLACEHOLDERS.items():\n",
    "        if any(k in up for k in keys):\n",
    "            return f\"<<{tag}>>\"\n",
    "    return None\n",
    "\n",
    "def extract_repls(row: pd.Series):\n",
    "    repl = []\n",
    "    for col, val in row.items():\n",
    "        if pd.isna(val): continue\n",
    "        ph = map_col(col)\n",
    "        if not ph:    continue\n",
    "        lit = str(val).strip()\n",
    "        if lit:\n",
    "            repl.append((re.escape(lit), ph))\n",
    "    return sorted(repl, key=lambda x: len(x[0]), reverse=True)\n",
    "\n",
    "# ── 1) Paths & load metadata ──────────────────────────────────────────\n",
    "META      = Path(\"../../../data/excel_manual_labeling/Daia_Manual_Labelling_granular.xlsx\")\n",
    "RAW_DIR   = Path(\"../../../data/original/golden_dataset_original\")\n",
    "JSON_OUT  = Path(\"../../../data/original/original_with_spans.json\")\n",
    "\n",
    "df = pd.read_excel(META, dtype=str)\n",
    "tag_re = re.compile(r\"<<([^>]+)>>\")\n",
    "\n",
    "output = []\n",
    "\n",
    "# ── 2) For each email, apply the same patterns to the original text ───\n",
    "for _, row in df.iterrows():\n",
    "    fname    = row[\"TextFile\"]\n",
    "    orig_txt = (RAW_DIR/fname).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    labels = []\n",
    "    for pattern, placeholder in extract_repls(row):\n",
    "        tag = tag_re.match(placeholder).group(1)  # e.g. \"VORNAME\"\n",
    "        # find all occurrences in the original\n",
    "        for m in re.finditer(pattern, orig_txt, flags=re.IGNORECASE):\n",
    "            labels.append({\n",
    "                \"start\": m.start(),\n",
    "                \"end\":   m.end(),\n",
    "                \"label\": tag\n",
    "            })\n",
    "\n",
    "    output.append({\n",
    "        \"file\":   fname,\n",
    "        \"text\":   orig_txt,\n",
    "        \"labels\": labels\n",
    "    })\n",
    "\n",
    "# ── 3) Write out ───────────────────────────────────────────────────────\n",
    "JSON_OUT.write_text(json.dumps(output, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(f\"✓ Wrote {len(output)} records to {JSON_OUT}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Wrote 160 records to ../../../data/original/original_with_spans.json\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "cb1aa8d2-a7f6-4f7a-8b64-02647927103f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T13:11:37.904028Z",
     "start_time": "2025-07-13T13:11:37.902793Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
