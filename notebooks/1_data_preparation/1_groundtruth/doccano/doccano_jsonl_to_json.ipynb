{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Doccano JSONL to JSON\n",
    "Combine original filenames with Doccano annotations into normalized ground truth JSON."
   ],
   "id": "b87450cb884b7819"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "\n",
    "# === Set file paths ===\n",
    "path_doccano_jsonl = \"../../../../data/original/doccano/doccano_groundtruth.jsonl\"\n",
    "path_original_json = \"../../../../data/original/golden_dataset_with_spans_norm.json\"\n",
    "output_path = \"../../../../data/original/ground_truth.json\"\n",
    "\n",
    "# === Load original JSON (with correct filenames)\n",
    "with open(path_original_json, \"r\", encoding=\"utf-8\") as f:\n",
    "    original_data = json.load(f)\n",
    "\n",
    "# === Load Doccano JSONL file\n",
    "doccano_data = []\n",
    "with open(path_doccano_jsonl, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        doccano_data.append(json.loads(line))\n",
    "\n",
    "# === Match by order and copy filename into new format\n",
    "converted = []\n",
    "for original_entry, doc_entry in zip(original_data, doccano_data):\n",
    "    converted.append({\n",
    "        \"file\": original_entry[\"file\"],  # Use filename from original\n",
    "        \"text\": doc_entry[\"text\"],\n",
    "        \"labels\": [\n",
    "            {\"start\": start, \"end\": end, \"label\": label}\n",
    "            for start, end, label in doc_entry.get(\"label\", [])\n",
    "        ]\n",
    "    })\n",
    "\n",
    "# === Write to new JSON file\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(converted, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ… Conversion complete. Output saved to: {output_path}\")"
   ],
   "id": "912930e87e5f335a"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
