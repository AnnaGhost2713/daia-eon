{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ddec6a3",
      "metadata": {
        "id": "3ddec6a3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import re\n",
        "import spacy\n",
        "import json\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdc6cb4d",
      "metadata": {
        "id": "fdc6cb4d"
      },
      "source": [
        "Label Mapping der einzelnen Identifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "45473a6b",
      "metadata": {
        "id": "45473a6b"
      },
      "outputs": [],
      "source": [
        "# Define priority for conflict resolution: higher values indicate stronger precedence\n",
        "PRIORITY_MAP = {\n",
        "    \"regex\": 3,       # Regex detections have the highest priority\n",
        "    \"piiranha\": 1,    # Piiranha has the lowest priority\n",
        "    \"spacy\": 2        # spaCy takes middle priority\n",
        "}\n",
        "\n",
        "# Define the set of labels that should be extracted\n",
        "TARGET_LABELS = [\n",
        "    \"TITEL\", \"VORNAME\", \"NACHNAME\", \"FIRMA\", \"TELEFONNUMMER\", \"EMAIL\", \"FAX\", \"STRASSE\",\n",
        "    \"HAUSNUMMER\", \"POSTLEITZAHL\", \"WOHNORT\", \"ZÄHLERNUMMER\", \"ZÄHLERSTAND\", \"VERTRAGSNUMMER\",\n",
        "    \"ZAHLUNG\", \"BANK\", \"IBAN\", \"BIC\", \"DATUM\", \"GESENDET_MIT\", \"LINK\"\n",
        "]\n",
        "\n",
        "# Maps labels from different sources (spaCy, Piiranha) to unified categories\n",
        "LABEL_MAP = {\n",
        "    # spaCy labels\n",
        "    \"PER\": \"NAME\",\n",
        "    \"LOC\": \"ADRESSE\",\n",
        "    \"ORG\": \"FIRMA\",\n",
        "    \"DATE\": \"DATUM\",\n",
        "    \"TIME\": \"DATUM\",\n",
        "    \"GPE\": \"ADRESSE\",\n",
        "    \"NORP\": \"GRUPPE\",\n",
        "    \"MONEY\": \"ZAHLUNG\",\n",
        "\n",
        "    # Piiranha labels\n",
        "    \"I-GIVENNAME\": \"NAME\",\n",
        "    \"I-SURNAME\": \"NAME\",\n",
        "    \"I-DATEOFBIRTH\": \"DATUM\",\n",
        "    \"I-EMAIL\": \"KONTAKT\",\n",
        "    \"I-TELEPHONENUM\": \"KONTAKT\",\n",
        "    \"I-USERNAME\": \"KONTAKT\",\n",
        "    \"I-CREDITCARDNUMBER\": \"ZAHLUNG\",\n",
        "    \"I-ACCOUNTNUM\": \"VERTRAG\",\n",
        "    \"I-BILLINGNUM\": \"VERTRAG\",\n",
        "    \"I-IDCARDNUM\": \"VERTRAG\",\n",
        "    \"I-TAXNUM\": \"VERTRAG\",\n",
        "    \"I-CITY\": \"ADRESSE\",\n",
        "    \"I-ZIPCODE\": \"ADRESSE\",\n",
        "    \"I-STREET\": \"ADRESSE\",\n",
        "    \"I-BUILDINGNUM\": \"ADRESSE\"\n",
        "}\n",
        "\n",
        "# Regular expression patterns used for matching key entity types\n",
        "REGEX_PATTERNS = {\n",
        "    # Strong and well-defined email pattern\n",
        "    \"EMAIL\": r\"\\b[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z]{2,}\\b\",\n",
        "\n",
        "    # IBAN pattern specific to German format (22 characters)\n",
        "    \"IBAN\": r\"\\bDE\\d{20}\\b\",\n",
        "\n",
        "    # BIC (SWIFT code) format\n",
        "    \"BIC\": r\"\\b[A-Z]{6}[A-Z2-9][A-NP-Z0-9]{1}([A-Z0-9]{3})?\\b\",\n",
        "\n",
        "    # URL pattern: includes http, https, or www\n",
        "    \"URL\": r\"\\bhttps?://[^\\s]+|www\\.[^\\s]+\\b\",\n",
        "\n",
        "    # Contract number pattern: must be prefixed by a keyword and contain digits\n",
        "    \"VERTRAG\": r\"\\b(vertragsnummer|vertragsnr\\.?|vnr|vn)[\\s:]{1,3}\\d{7,10}\\b\",\n",
        "\n",
        "    # Well-formed dates, including ISO and German styles\n",
        "    \"DATUM\": (\n",
        "        r\"\\b\\d{2}\\.\\d{2}\\.\\d{4}\\b|\"      # e.g., 15.08.2024\n",
        "        r\"\\b\\d{4}-\\d{2}-\\d{2}\\b|\"        # e.g., 2024-08-15\n",
        "        r\"\\b(19|20)\\d{2}\\b\"              # Four-digit years\n",
        "    ),\n",
        "\n",
        "    # German phone number format, must include country code\n",
        "    \"TELEFON\": r\"\\b\\+49\\s?\\d[\\d\\s/-]{6,}\\b\",\n",
        "\n",
        "    # Alphanumeric meter numbers, typically longer than 10 characters\n",
        "    \"ZÄHLERNUMMER\": r\"\\b[A-Z]{2}[A-Z0-9]{8,}\\b\",\n",
        "\n",
        "    # Payment amount pattern: includes currency keywords\n",
        "    \"ZAHLUNG\": r\"\\b\\d{1,5}[.,]\\d{2}\\s?(€|Euro|EUR|Cent)\\b\",\n",
        "\n",
        "    # Street pattern: must end with common street suffixes\n",
        "    \"STRASSE\": r\"\\b\\w+(straße|gasse|allee|weg|platz|str\\.|grund)\\b\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4cc5acd",
      "metadata": {
        "id": "f4cc5acd"
      },
      "source": [
        "PIIranha Spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "12368595",
      "metadata": {
        "id": "12368595"
      },
      "outputs": [],
      "source": [
        "# Load the Piiranha model and tokenizer from HuggingFace\n",
        "model_name = \"iiiorg/piiranha-v1-detect-personal-information\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "\n",
        "# Select device: GPU if available, otherwise CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Function to extract entity spans from text using Piiranha\n",
        "def get_piiranha_spans(text):\n",
        "    # Tokenize input and get offset mappings (to map tokens back to character positions)\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, return_offsets_mapping=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")[0].tolist()\n",
        "\n",
        "    # Inference: get model predictions without gradient calculation\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)[0].tolist()\n",
        "\n",
        "    spans = []\n",
        "    current_label = None\n",
        "    current_start = None\n",
        "\n",
        "    # Iterate over each token and its offset\n",
        "    for i, (start, end) in enumerate(offset_mapping):\n",
        "        if start == end:\n",
        "            continue  # Skip special tokens like [CLS], [SEP]\n",
        "\n",
        "        # Get predicted label and map it to a simplified label name\n",
        "        raw_label = model.config.id2label[predictions[i]]\n",
        "        mapped_label = LABEL_MAP.get(raw_label, None)\n",
        "\n",
        "        # If the label is one of the target labels, track span start and continuation\n",
        "        if mapped_label in TARGET_LABELS:\n",
        "            if current_label == mapped_label:\n",
        "                continue  # Continue current span\n",
        "            else:\n",
        "                # If label changes, close previous span and start new one\n",
        "                if current_label is not None:\n",
        "                    spans.append({\"start\": current_start, \"end\": offset_mapping[i-1][1], \"label\": current_label})\n",
        "                current_label = mapped_label\n",
        "                current_start = start\n",
        "        else:\n",
        "            # If no valid label, close previous span if one was open\n",
        "            if current_label is not None:\n",
        "                spans.append({\"start\": current_start, \"end\": offset_mapping[i-1][1], \"label\": current_label})\n",
        "                current_label = None\n",
        "                current_start = None\n",
        "\n",
        "    # Finalize last span if still open\n",
        "    if current_label is not None:\n",
        "        spans.append({\"start\": current_start, \"end\": offset_mapping[-1][1], \"label\": current_label})\n",
        "\n",
        "    return spans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "899f7f6a",
      "metadata": {
        "id": "899f7f6a"
      },
      "source": [
        "SpaCy Ruler laden & Spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b11c54ec",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model with EntityRuler saved at: C:\\Users\\morit\\OneDrive\\Uni\\02_Master\\05_Studium\\02_Semester_II\\Data Analytics in Applications\\VSCode\\daia-eon\\notebooks\\3_model_training_and_testing\\spacy_pipeline\\piiranha_refinement\\custom_spacy_model_with_ruler\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# Select the spaCy model\n",
        "# -----------------------------\n",
        "\n",
        "# Load the spaCy model depending on your setup\n",
        "# Uncomment one of the following if needed\n",
        "\n",
        "# Trained on synthetic data (SynthB)\n",
        "# nlp = spacy.load(\"../custom_spacy_model_synthetic_data_b_push\")\n",
        "\n",
        "# Trained on original data (OrigData)\n",
        "# nlp = spacy.load(\"../custom_spacy_model_doccano_labeling\")\n",
        "\n",
        "# Untrained base model\n",
        "nlp = spacy.load(\"de_core_news_md\")\n",
        "\n",
        "# Toggle for activating EntityRuler\n",
        "use_ruler = True\n",
        "\n",
        "if use_ruler:\n",
        "    # Remove existing entity_ruler if present\n",
        "    if \"entity_ruler\" in nlp.pipe_names:\n",
        "        nlp.remove_pipe(\"entity_ruler\")\n",
        "\n",
        "    # Add a new entity_ruler before the NER component\n",
        "    ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
        "\n",
        "    # Define patterns (Regex-based, no Gazetteer)\n",
        "    strasse_patterns = [\n",
        "        {\n",
        "            \"label\": \"STRASSE\",\n",
        "            \"pattern\": [\n",
        "                {\"TEXT\": {\"REGEX\": r\".*(straße|gasse|allee|weg|platz|str.|grund)$\"}},\n",
        "                {\"TEXT\": {\"REGEX\": r\"^\\d+[a-zA-Z]?$\"}}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    vertragsnummer_patterns = [\n",
        "        {\n",
        "            \"label\": \"VERTRAGSNUMMER\",\n",
        "            \"pattern\": [\n",
        "                {\"LOWER\": {\"IN\": [\"vertragsnummer\", \"vertragsnr.\", \"vnr\", \"vn\"]}},\n",
        "                {\"IS_PUNCT\": True, \"OP\": \"*\"},\n",
        "                {\"TEXT\": {\"REGEX\": r\"^\\d{6,12}\\\\.?$\"}}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    kundennummer_patterns = [\n",
        "        {\n",
        "            \"label\": \"KUNDENNUMMER\",\n",
        "            \"pattern\": [\n",
        "                {\"LOWER\": {\"IN\": [\"kundennummer\", \"kundennr.\", \"kdnr\", \"kd\"]}},\n",
        "                {\"IS_PUNCT\": True, \"OP\": \"*\"},\n",
        "                {\"TEXT\": {\"REGEX\": r\"^\\d{6,12}\\\\.?$\"}}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    zahlung_pattern = [\n",
        "        {\n",
        "            \"label\": \"ZAHLUNG\",\n",
        "            \"pattern\": [\n",
        "                {\"TEXT\": {\"REGEX\": r\"^\\d+[.,]?\\d{0,2}$\"}},\n",
        "                {\"TEXT\": {\"REGEX\": r\"^(\\u20ac|euro|eur)$\"}}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    email_pattern = [\n",
        "        {\n",
        "            \"label\": \"EMAIL\",\n",
        "            \"pattern\": [\n",
        "                {\"TEXT\": {\"REGEX\": r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w{2,}$\"}}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    telefon_pattern = [\n",
        "        {\n",
        "            \"label\": \"TELEFON\",\n",
        "            \"pattern\": [\n",
        "                {\"TEXT\": {\"REGEX\": r\"^(\\+49|0)[\\d\\s/-]{7,}$\"}}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    url_pattern = [\n",
        "        {\n",
        "            \"label\": \"LINK\",\n",
        "            \"pattern\": [\n",
        "                {\"TEXT\": {\"REGEX\": r\"^https?://[\\w\\-\\.]+\\.\\w{2,}(/[\\w\\-\\.]*)*$\"}}\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"label\": \"LINK\",\n",
        "            \"pattern\": [\n",
        "                {\"TEXT\": {\"REGEX\": r\"^www\\.[\\w\\-\\.]+\\.\\w{2,}(/[\\w\\-\\.]*)*$\"}}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    datum_pattern = [\n",
        "        {\n",
        "            \"label\": \"DATUM\",\n",
        "            \"pattern\": [\n",
        "                {\"TEXT\": {\"REGEX\": r\"^(\\d{1,2}[./-]){2}\\d{2,4}$\"}}\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"label\": \"DATUM\",\n",
        "            \"pattern\": [\n",
        "                {\"TEXT\": {\"REGEX\": r\"^\\d{4}-\\d{2}-\\d{2}$\"}}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Add all patterns to the ruler\n",
        "    ruler.add_patterns(\n",
        "        zahlung_pattern + url_pattern + email_pattern + telefon_pattern +\n",
        "        strasse_patterns + vertragsnummer_patterns + kundennummer_patterns + datum_pattern\n",
        "    )\n",
        "\n",
        "    # (Optional) Save model with EntityRuler\n",
        "    output_dir_ruler = Path(\"custom_spacy_model_with_ruler\")\n",
        "    output_dir_ruler.mkdir(exist_ok=True)\n",
        "    nlp.to_disk(output_dir_ruler)\n",
        "    print(f\"✅ Model with EntityRuler saved at: {output_dir_ruler.resolve()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4b396a76",
      "metadata": {
        "id": "4b396a76"
      },
      "outputs": [],
      "source": [
        "def get_spacy_spans(text):\n",
        "    doc = nlp(text)\n",
        "    spans = []\n",
        "    for ent in doc.ents:\n",
        "        label = LABEL_MAP.get(ent.label_, ent.label_)\n",
        "        if label in TARGET_LABELS:\n",
        "            spans.append({\"start\": ent.start_char, \"end\": ent.end_char, \"label\": label})\n",
        "    return spans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e73e8a11",
      "metadata": {
        "id": "e73e8a11"
      },
      "source": [
        "Regex Spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d80d052d",
      "metadata": {
        "id": "d80d052d"
      },
      "outputs": [],
      "source": [
        "def get_regex_spans(text):\n",
        "    spans = []\n",
        "    for raw_label, pattern in REGEX_PATTERNS.items():\n",
        "        mapped_label = LABEL_MAP.get(raw_label, raw_label)  # bleibt bei IBAN = IBAN\n",
        "        if mapped_label not in TARGET_LABELS:\n",
        "            continue\n",
        "        for match in re.finditer(pattern, text):\n",
        "            spans.append({\n",
        "                \"start\": match.start(),\n",
        "                \"end\": match.end(),\n",
        "                \"label\": mapped_label\n",
        "            })\n",
        "    return spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "9833fe90",
      "metadata": {
        "id": "9833fe90",
        "outputId": "add03921-f577-4f08-a1c8-8a4b994dfb1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "[{'start': 103, 'end': 113, 'label': 'EMAIL'}, {'start': 154, 'end': 161, 'label': 'ZAHLUNG'}]\n",
            "[{'start': 103, 'end': 113, 'label': 'EMAIL'}, {'start': 177, 'end': 181, 'label': 'DATUM'}]\n"
          ]
        }
      ],
      "source": [
        "# Beispieltext zum Testen\n",
        "sample_text = \"\"\"\n",
        "Sehr geehrter Herr John Doe,\n",
        "Ihre Kundennummer 4012345678 ist aktiv.\n",
        "Bitte kontaktieren Sie uns unter max@eon.de oder +49 171 1234567.\n",
        "Ihre Zahlung über 89,99 € wurde am 15-08-2024 verbucht.\n",
        "\"\"\"\n",
        "\n",
        "# PIIranha-Spans abrufen\n",
        "piiranha_spans = get_piiranha_spans(sample_text)\n",
        "spacy_spans = get_spacy_spans(sample_text)\n",
        "regex_spans = get_regex_spans(sample_text)\n",
        "\n",
        "# Ergebnisse ausgeben\n",
        "print(piiranha_spans)\n",
        "print(spacy_spans)\n",
        "print(regex_spans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "de382f01",
      "metadata": {
        "id": "de382f01"
      },
      "outputs": [],
      "source": [
        "# 🧠 Optional: Merge overlapping or duplicate spans by sorting them\n",
        "def merge_spans(spans):\n",
        "    return sorted(spans, key=lambda x: x['start'])\n",
        "\n",
        "# 🔄 Resolve conflicts between overlapping spans based on priority\n",
        "def resolve_conflicts(spans):\n",
        "    # Sort spans: first by start index, then by descending length (longer first), then by priority\n",
        "    spans = sorted(\n",
        "        spans,\n",
        "        key=lambda x: (\n",
        "            x[\"start\"],\n",
        "            -(x[\"end\"] - x[\"start\"]),\n",
        "            -PRIORITY_MAP.get(x.get(\"source\", \"\"), 0)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    resolved = []\n",
        "    occupied = set()\n",
        "\n",
        "    for span in spans:\n",
        "        span_range = set(range(span[\"start\"], span[\"end\"]))\n",
        "        conflict = False\n",
        "\n",
        "        for existing in resolved:\n",
        "            existing_range = set(range(existing[\"start\"], existing[\"end\"]))\n",
        "\n",
        "            # ❌ If spans overlap\n",
        "            if span_range & existing_range:\n",
        "                # ➕ If one span is fully inside the other → decide based on priority\n",
        "                if span[\"start\"] >= existing[\"start\"] and span[\"end\"] <= existing[\"end\"]:\n",
        "                    if PRIORITY_MAP[span[\"source\"]] > PRIORITY_MAP[existing[\"source\"]]:\n",
        "                        resolved.remove(existing)\n",
        "                        break\n",
        "                    else:\n",
        "                        conflict = True\n",
        "                        break\n",
        "                elif existing[\"start\"] >= span[\"start\"] and existing[\"end\"] <= span[\"end\"]:\n",
        "                    if PRIORITY_MAP[span[\"source\"]] < PRIORITY_MAP[existing[\"source\"]]:\n",
        "                        conflict = True\n",
        "                        break\n",
        "                    else:\n",
        "                        resolved.remove(existing)\n",
        "                        break\n",
        "                else:\n",
        "                    # True overlap, not nested – reject current span\n",
        "                    conflict = True\n",
        "                    break\n",
        "\n",
        "        if not conflict:\n",
        "            resolved.append(span)\n",
        "            occupied.update(span_range)\n",
        "\n",
        "    return resolved\n",
        "\n",
        "# 🔐 Apply final redaction using label numbering (e.g., NAME_1, NAME_2, ...)\n",
        "def apply_final_redaction(text, spans):\n",
        "    spans = sorted(spans, key=lambda x: x[\"start\"])\n",
        "    redacted = []\n",
        "    last_index = 0\n",
        "    label_counter = defaultdict(int)\n",
        "\n",
        "    for span in spans:\n",
        "        label = span[\"label\"]\n",
        "        label_counter[label] += 1\n",
        "        label_with_id = f\"{label}_{label_counter[label]}\"\n",
        "\n",
        "        # Keep text before the span\n",
        "        redacted.append(text[last_index:span[\"start\"]])\n",
        "        # Insert replacement token\n",
        "        redacted.append(f\"[{label_with_id}]\")\n",
        "        # Update position pointer\n",
        "        last_index = span[\"end\"]\n",
        "\n",
        "    # Append any remaining text\n",
        "    redacted.append(text[last_index:])\n",
        "    return ''.join(redacted)\n",
        "\n",
        "# 🧩 Main masking function using multiple components (e.g., regex, spacy, piiranha)\n",
        "def mask_text_with_all(text, components=[\"regex\"]):\n",
        "    all_spans = []\n",
        "\n",
        "    if \"regex\" in components:\n",
        "        for span in get_regex_spans(text):\n",
        "            span[\"source\"] = \"regex\"\n",
        "            all_spans.append(span)\n",
        "\n",
        "    if \"piiranha\" in components:\n",
        "        for span in get_piiranha_spans(text):\n",
        "            span[\"source\"] = \"piiranha\"\n",
        "            all_spans.append(span)\n",
        "\n",
        "    if \"spacy\" in components:\n",
        "        for span in get_spacy_spans(text):\n",
        "            span[\"source\"] = \"spacy\"\n",
        "            all_spans.append(span)\n",
        "\n",
        "    # 🔧 Resolve span conflicts and apply redaction\n",
        "    spans = resolve_conflicts(all_spans)\n",
        "    merged = merge_spans(spans)\n",
        "    return apply_final_redaction(text, merged)\n",
        "\n",
        "# 🎯 Mask text using only a single component (for testing or analysis)\n",
        "def mask_text_with_single_component(text, component=\"regex\"):\n",
        "    if component == \"regex\":\n",
        "        all_spans = get_regex_spans(text)\n",
        "    elif component == \"piiranha\":\n",
        "        all_spans = get_piiranha_spans(text)\n",
        "    elif component == \"spacy\":\n",
        "        all_spans = get_spacy_spans(text)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown component: {component}\")\n",
        "\n",
        "    # Optionally resolve internal conflicts within single component spans\n",
        "    spans = resolve_conflicts(all_spans)\n",
        "    merged = merge_spans(spans)\n",
        "\n",
        "    # Return the redacted version of the input text\n",
        "    return apply_final_redaction(text, merged)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "601fabb9",
      "metadata": {
        "id": "601fabb9",
        "outputId": "b6ab037f-ba0f-4ef2-b293-d04258445f3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "[{'start': 0, 'end': 10, 'label': 'DATUM'}]\n",
            "[{'start': 0, 'end': 10, 'label': 'DATUM'}]\n",
            "[DATUM_1]\n",
            " Mein Name ist Isabelle Eckhauer : (+49 (0) 5402 008802)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sample = \"01.08.2023\\n Mein Name ist Isabelle Eckhauer : (+49 (0) 5402 008802)\\n\"\n",
        "        \n",
        "print(get_piiranha_spans(sample))\n",
        "print(get_spacy_spans(sample))\n",
        "print(get_regex_spans(sample))\n",
        "\n",
        "text = mask_text_with_all(sample)\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "42b3e31e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation results saved to: evaluation_entity_level_combined.csv\n"
          ]
        }
      ],
      "source": [
        "# Load ground truth test data\n",
        "with open(\"../../../../data/original/ground_truth_split/test_norm.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "# Helper function: convert span dictionary to tuple\n",
        "def to_tuple(span):\n",
        "    return (span[\"start\"], span[\"end\"], span[\"label\"])\n",
        "\n",
        "# Evaluate predicted spans against gold standard\n",
        "def evaluate_entities(pred_fn, data, threshold=0.8):\n",
        "    stats = defaultdict(lambda: {\"tp\": 0, \"fp\": 0, \"fn\": 0})\n",
        "    total_tp = total_fp = total_fn = 0\n",
        "\n",
        "    for entry in data:\n",
        "        text = entry[\"text\"]\n",
        "        gold_spans = [to_tuple(s) for s in entry[\"labels\"]]\n",
        "        pred_spans = [to_tuple(s) for s in pred_fn(text)]\n",
        "        matched_gold = set()\n",
        "        matched_pred = set()\n",
        "\n",
        "        # Try to match each predicted span with a gold span using Jaccard similarity\n",
        "        for pi, p in enumerate(pred_spans):\n",
        "            best_match = None\n",
        "            best_overlap = 0\n",
        "            for gi, g in enumerate(gold_spans):\n",
        "                if g[2] != p[2]:  # Only match if labels are the same\n",
        "                    continue\n",
        "                overlap = max(0, min(p[1], g[1]) - max(p[0], g[0]))\n",
        "                union = max(p[1], g[1]) - min(p[0], g[0])\n",
        "                jaccard = overlap / union if union > 0 else 0\n",
        "                if jaccard >= threshold and jaccard > best_overlap:\n",
        "                    best_overlap = jaccard\n",
        "                    best_match = gi\n",
        "            if best_match is not None:\n",
        "                matched_gold.add(best_match)\n",
        "                matched_pred.add(pi)\n",
        "                stats[p[2]][\"tp\"] += 1\n",
        "                total_tp += 1\n",
        "\n",
        "        # Count false positives: predicted spans without gold match\n",
        "        for i, p in enumerate(pred_spans):\n",
        "            if i not in matched_pred:\n",
        "                stats[p[2]][\"fp\"] += 1\n",
        "                total_fp += 1\n",
        "\n",
        "        # Count false negatives: gold spans without prediction\n",
        "        for i, g in enumerate(gold_spans):\n",
        "            if i not in matched_gold:\n",
        "                stats[g[2]][\"fn\"] += 1\n",
        "                total_fn += 1\n",
        "\n",
        "    # Convert statistics to rows for DataFrame\n",
        "    rows = []\n",
        "    for label, counts in stats.items():\n",
        "        tp, fp, fn = counts[\"tp\"], counts[\"fp\"], counts[\"fn\"]\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall    = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1        = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        rows.append({\n",
        "            \"component\": \"Combined\",\n",
        "            \"label\": label,\n",
        "            \"tp\": tp,\n",
        "            \"fp\": fp,\n",
        "            \"fn\": fn,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1\": f1\n",
        "        })\n",
        "\n",
        "    # Add overall performance row\n",
        "    overall_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
        "    overall_recall    = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
        "    overall_f1        = 2 * overall_precision * overall_recall / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0\n",
        "\n",
        "    rows.append({\n",
        "        \"component\": \"Combined\",\n",
        "        \"label\": \"OVERALL\",\n",
        "        \"tp\": total_tp,\n",
        "        \"fp\": total_fp,\n",
        "        \"fn\": total_fn,\n",
        "        \"precision\": overall_precision,\n",
        "        \"recall\": overall_recall,\n",
        "        \"f1\": overall_f1\n",
        "    })\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# Prediction function that combines multiple components and resolves conflicts\n",
        "def run_combined_spans(text):\n",
        "    all_spans = []\n",
        "\n",
        "    # Uncomment if you want to use additional components\n",
        "    '''\n",
        "    for span in get_regex_spans(text):\n",
        "        span[\"source\"] = \"regex\"\n",
        "        all_spans.append(span)\n",
        "\n",
        "    for span in get_piiranha_spans(text):\n",
        "        span[\"source\"] = \"piiranha\"\n",
        "        all_spans.append(span)\n",
        "    '''\n",
        "\n",
        "    for span in get_spacy_spans(text):\n",
        "        span[\"source\"] = \"spacy\"\n",
        "        all_spans.append(span)\n",
        "\n",
        "    resolved = resolve_conflicts(all_spans)\n",
        "    return merge_spans(resolved)\n",
        "\n",
        "# Execute evaluation and export results\n",
        "df_eval = evaluate_entities(run_combined_spans, test_data, threshold=0.5)\n",
        "df_eval.to_csv(\"Results_synthetic_data_b_only_spacy_no_ruler.csv\", index=False)\n",
        "print(\"Evaluation results saved to: evaluation_entity_level_combined.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "eeb8ee11",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>component</th>\n",
              "      <th>label</th>\n",
              "      <th>tp</th>\n",
              "      <th>fp</th>\n",
              "      <th>fn</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Combined</td>\n",
              "      <td>LINK</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Combined</td>\n",
              "      <td>FIRMA</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.315789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Combined</td>\n",
              "      <td>ZAHLUNG</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.545455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Combined</td>\n",
              "      <td>GESENDET_MIT</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Combined</td>\n",
              "      <td>VERTRAGSNUMMER</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Combined</td>\n",
              "      <td>VORNAME</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Combined</td>\n",
              "      <td>NACHNAME</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Combined</td>\n",
              "      <td>DATUM</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.461538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Combined</td>\n",
              "      <td>IBAN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Combined</td>\n",
              "      <td>TITEL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Combined</td>\n",
              "      <td>TELEFONNUMMER</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Combined</td>\n",
              "      <td>ZÄHLERNUMMER</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Combined</td>\n",
              "      <td>ZÄHLERSTAND</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Combined</td>\n",
              "      <td>STRASSE</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.476190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Combined</td>\n",
              "      <td>EMAIL</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.888889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Combined</td>\n",
              "      <td>POSTLEITZAHL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Combined</td>\n",
              "      <td>WOHNORT</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Combined</td>\n",
              "      <td>HAUSNUMMER</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Combined</td>\n",
              "      <td>FAX</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Combined</td>\n",
              "      <td>BANK</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Combined</td>\n",
              "      <td>OVERALL</td>\n",
              "      <td>27</td>\n",
              "      <td>11</td>\n",
              "      <td>293</td>\n",
              "      <td>0.710526</td>\n",
              "      <td>0.084375</td>\n",
              "      <td>0.150838</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   component           label  tp  fp   fn  precision    recall        f1\n",
              "0   Combined            LINK   3   1    0   0.750000  1.000000  0.857143\n",
              "1   Combined           FIRMA   3  10    3   0.230769  0.500000  0.315789\n",
              "2   Combined         ZAHLUNG   3   0    5   1.000000  0.375000  0.545455\n",
              "3   Combined    GESENDET_MIT   0   0    6   0.000000  0.000000  0.000000\n",
              "4   Combined  VERTRAGSNUMMER   0   0   40   0.000000  0.000000  0.000000\n",
              "5   Combined         VORNAME   0   0   57   0.000000  0.000000  0.000000\n",
              "6   Combined        NACHNAME   0   0   61   0.000000  0.000000  0.000000\n",
              "7   Combined           DATUM   9   0   21   1.000000  0.300000  0.461538\n",
              "8   Combined            IBAN   0   0    4   0.000000  0.000000  0.000000\n",
              "9   Combined           TITEL   0   0    8   0.000000  0.000000  0.000000\n",
              "10  Combined   TELEFONNUMMER   0   0   14   0.000000  0.000000  0.000000\n",
              "11  Combined    ZÄHLERNUMMER   0   0    6   0.000000  0.000000  0.000000\n",
              "12  Combined     ZÄHLERSTAND   0   0    3   0.000000  0.000000  0.000000\n",
              "13  Combined         STRASSE   5   0   11   1.000000  0.312500  0.476190\n",
              "14  Combined           EMAIL   4   0    1   1.000000  0.800000  0.888889\n",
              "15  Combined    POSTLEITZAHL   0   0   16   0.000000  0.000000  0.000000\n",
              "16  Combined         WOHNORT   0   0   18   0.000000  0.000000  0.000000\n",
              "17  Combined      HAUSNUMMER   0   0   16   0.000000  0.000000  0.000000\n",
              "18  Combined             FAX   0   0    2   0.000000  0.000000  0.000000\n",
              "19  Combined            BANK   0   0    1   0.000000  0.000000  0.000000\n",
              "20  Combined         OVERALL  27  11  293   0.710526  0.084375  0.150838"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "id": "065952e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_error_spans(pred_fn, data, threshold=0.8):\n",
        "    false_positives = []\n",
        "    false_negatives = []\n",
        "\n",
        "    def to_tuple(span):\n",
        "        return (span[\"start\"], span[\"end\"], span[\"label\"])\n",
        "\n",
        "    for entry in data:\n",
        "        text = entry[\"text\"]\n",
        "        gold_spans = [to_tuple(s) for s in entry[\"labels\"]]\n",
        "        pred_spans = [to_tuple(s) for s in pred_fn(text)]\n",
        "        matched_gold = set()\n",
        "        matched_pred = set()\n",
        "\n",
        "        for pi, p in enumerate(pred_spans):\n",
        "            for gi, g in enumerate(gold_spans):\n",
        "                if g[2] != p[2]:\n",
        "                    continue\n",
        "                # Overlap berechnen\n",
        "                overlap = max(0, min(p[1], g[1]) - max(p[0], g[0]))\n",
        "                union = max(p[1], g[1]) - min(p[0], g[0])\n",
        "                jaccard = overlap / union if union > 0 else 0\n",
        "                if jaccard >= threshold:\n",
        "                    matched_gold.add(gi)\n",
        "                    matched_pred.add(pi)\n",
        "                    break  # nur erster Treffer zählt\n",
        "\n",
        "        # False Positives\n",
        "        for pi, p in enumerate(pred_spans):\n",
        "            if pi not in matched_pred:\n",
        "                false_positives.append({\n",
        "                    \"type\": \"FP\",\n",
        "                    \"text\": text[p[0]:p[1]],\n",
        "                    \"label\": p[2],\n",
        "                    \"start\": p[0],\n",
        "                    \"end\": p[1],\n",
        "                    \"source\": \"pred_only\"\n",
        "                })\n",
        "\n",
        "        # False Negatives\n",
        "        for gi, g in enumerate(gold_spans):\n",
        "            if gi not in matched_gold:\n",
        "                false_negatives.append({\n",
        "                    \"type\": \"FN\",\n",
        "                    \"text\": text[g[0]:g[1]],\n",
        "                    \"label\": g[2],\n",
        "                    \"start\": g[0],\n",
        "                    \"end\": g[1],\n",
        "                    \"source\": \"gold_only\"\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(false_positives + false_negatives)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "id": "3e2866e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_errors = extract_error_spans(run_combined_spans, test_data, threshold=0.1)\n",
        "df_errors.to_csv(\"error_analysis_partial_match.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "id": "0adf965d",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_component_spans(text, components=[\"spacy\"]):\n",
        "    all_spans = []\n",
        "\n",
        "    if \"regex\" in components:\n",
        "        for span in get_regex_spans(text):\n",
        "            span[\"source\"] = \"regex\"\n",
        "            all_spans.append(span)\n",
        "\n",
        "    if \"piiranha\" in components:\n",
        "        for span in get_piiranha_spans(text):\n",
        "            span[\"source\"] = \"piiranha\"\n",
        "            all_spans.append(span)\n",
        "\n",
        "    if \"spacy\" in components:\n",
        "        for span in get_spacy_spans(text):\n",
        "            span[\"source\"] = \"spacy\"\n",
        "            all_spans.append(span)\n",
        "\n",
        "    resolved = resolve_conflicts(all_spans)\n",
        "    return merge_spans(resolved)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "id": "8f08fdf3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   component    label  tp  fp   fn  precision    recall        f1\n",
            "20     spaCy  OVERALL   3  10  317   0.230769  0.009375  0.018018\n",
            "41  Piiranha  OVERALL   2   0  318   1.000000  0.006250  0.012422\n",
            "63     Regex  OVERALL  29   8  291   0.783784  0.090625  0.162465\n",
            "85  Combined  OVERALL  32  18  288   0.640000  0.100000  0.172973\n"
          ]
        }
      ],
      "source": [
        "# Evaluation nur mit spaCy\n",
        "df_spacy = evaluate_entities(lambda text: run_component_spans(text, [\"spacy\"]), test_data, threshold=0.5)\n",
        "df_spacy[\"component\"] = \"spaCy\"\n",
        "\n",
        "# Evaluation nur mit Piiranha\n",
        "df_piiranha = evaluate_entities(lambda text: run_component_spans(text, [\"piiranha\"]), test_data, threshold=0.5)\n",
        "df_piiranha[\"component\"] = \"Piiranha\"\n",
        "\n",
        "# Evaluation nur mit Regex\n",
        "df_regex = evaluate_entities(lambda text: run_component_spans(text, [\"regex\"]), test_data, threshold=0.5)\n",
        "df_regex[\"component\"] = \"Regex\"\n",
        "\n",
        "# Evaluation kombiniert (optional)\n",
        "df_combined = evaluate_entities(lambda text: run_component_spans(text, [\"regex\", \"piiranha\", \"spacy\"]), test_data, threshold=0.5)\n",
        "df_combined[\"component\"] = \"Combined\"\n",
        "\n",
        "# Zusammenführen\n",
        "df_all = pd.concat([df_spacy, df_piiranha, df_regex, df_combined], ignore_index=True)\n",
        "\n",
        "# Nur OVERALL-Zeilen anzeigen\n",
        "df_overall = df_all[df_all[\"label\"] == \"OVERALL\"]\n",
        "\n",
        "# CSV speichern\n",
        "df_overall.to_csv(\"Results_entity_level_all_components_overall.csv\", index=False)\n",
        "\n",
        "# Anzeigen\n",
        "print(df_overall)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.11.9)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
