{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 193,
      "id": "3ddec6a3",
      "metadata": {
        "id": "3ddec6a3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import re\n",
        "import spacy\n",
        "import json\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from collections import defaultdict, Counter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "id": "3e681a55",
      "metadata": {},
      "outputs": [],
      "source": [
        "#Pipeline Configuration\n",
        "\n",
        "#Selected usage of single components\n",
        "use_spacy = True\n",
        "use_regex = False\n",
        "use_piiranha = False\n",
        "\n",
        "# Select the spaCy model\n",
        "\n",
        "# Load the spaCy model depending on your setup\n",
        "# Uncomment one of the following if needed\n",
        "\n",
        "# Trained on synthetic data (SynthB)\n",
        "#nlp = spacy.load(\"../custom_spacy_model_synthetic_data_b_push\")\n",
        "#nlp_name = \"synthetic_b\"\n",
        "\n",
        "# Trained on original data (OrigData)\n",
        "nlp = spacy.load(\"../custom_spacy_model_doccano_labeling\")\n",
        "nlp_name = \"orginal\"\n",
        "\n",
        "# Untrained base model\n",
        "#nlp = spacy.load(\"de_core_news_md\")\n",
        "#nlp_name = \"untrained\"\n",
        "\n",
        "# Toggle for activating EntityRuler\n",
        "use_ruler = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdc6cb4d",
      "metadata": {
        "id": "fdc6cb4d"
      },
      "source": [
        "Label Mapping der einzelnen Identifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "id": "45473a6b",
      "metadata": {
        "id": "45473a6b"
      },
      "outputs": [],
      "source": [
        "# Define priority for conflict resolution: higher values indicate stronger precedence\n",
        "PRIORITY_MAP = {\n",
        "    \"regex\": 3,       # Regex detections have the highest priority\n",
        "    \"piiranha\": 1,    # Piiranha has the lowest priority\n",
        "    \"spacy\": 2        # spaCy takes middle priority\n",
        "}\n",
        "\n",
        "# Define the set of labels that should be extracted\n",
        "TARGET_LABELS = [\n",
        "    \"TITEL\", \"VORNAME\", \"NACHNAME\", \"FIRMA\", \"TELEFONNUMMER\", \"EMAIL\", \"FAX\", \"STRASSE\",\n",
        "    \"HAUSNUMMER\", \"POSTLEITZAHL\", \"WOHNORT\", \"ZÄHLERNUMMER\", \"ZÄHLERSTAND\", \"VERTRAGSNUMMER\",\n",
        "    \"ZAHLUNG\", \"BANK\", \"IBAN\", \"BIC\", \"DATUM\", \"GESENDET_MIT\", \"LINK\"\n",
        "]\n",
        "\n",
        "# Maps labels from different sources (spaCy, Piiranha) to unified categories\n",
        "LABEL_MAP = {\n",
        "    # spaCy labels\n",
        "    \"PER\": \"NAME\",\n",
        "    \"LOC\": \"ADRESSE\",\n",
        "    \"ORG\": \"FIRMA\",\n",
        "    \"DATE\": \"DATUM\",\n",
        "    \"TIME\": \"DATUM\",\n",
        "    \"GPE\": \"ADRESSE\",\n",
        "    \"NORP\": \"GRUPPE\",\n",
        "    \"MONEY\": \"ZAHLUNG\",\n",
        "\n",
        "    # Piiranha labels\n",
        "    \"I-GIVENNAME\": \"NAME\",\n",
        "    \"I-SURNAME\": \"NAME\",\n",
        "    \"I-DATEOFBIRTH\": \"DATUM\",\n",
        "    \"I-EMAIL\": \"KONTAKT\",\n",
        "    \"I-TELEPHONENUM\": \"KONTAKT\",\n",
        "    \"I-USERNAME\": \"KONTAKT\",\n",
        "    \"I-CREDITCARDNUMBER\": \"ZAHLUNG\",\n",
        "    \"I-ACCOUNTNUM\": \"VERTRAG\",\n",
        "    \"I-BILLINGNUM\": \"VERTRAG\",\n",
        "    \"I-IDCARDNUM\": \"VERTRAG\",\n",
        "    \"I-TAXNUM\": \"VERTRAG\",\n",
        "    \"I-CITY\": \"ADRESSE\",\n",
        "    \"I-ZIPCODE\": \"ADRESSE\",\n",
        "    \"I-STREET\": \"ADRESSE\",\n",
        "    \"I-BUILDINGNUM\": \"ADRESSE\"\n",
        "}\n",
        "\n",
        "# Regular expression patterns used for matching key entity types\n",
        "REGEX_PATTERNS = {\n",
        "    # Strong and well-defined email pattern\n",
        "    \"EMAIL\": r\"\\b[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z]{2,}\\b\",\n",
        "\n",
        "    # IBAN pattern specific to German format (22 characters)\n",
        "    \"IBAN\": r\"\\bDE\\d{20}\\b\",\n",
        "\n",
        "    # BIC (SWIFT code) format\n",
        "    \"BIC\": r\"\\b[A-Z]{6}[A-Z2-9][A-NP-Z0-9]{1}([A-Z0-9]{3})?\\b\",\n",
        "\n",
        "    # URL pattern: includes http, https, or www\n",
        "    \"URL\": r\"\\bhttps?://[^\\s]+|www\\.[^\\s]+\\b\",\n",
        "\n",
        "    # Contract number pattern: must be prefixed by a keyword and contain digits\n",
        "    \"VERTRAG\": r\"\\b(vertragsnummer|vertragsnr\\.?|vnr|vn)[\\s:]{1,3}\\d{7,10}\\b\",\n",
        "\n",
        "    # Well-formed dates, including ISO and German styles\n",
        "    \"DATUM\": (\n",
        "        r\"\\b\\d{2}\\.\\d{2}\\.\\d{4}\\b|\"      # e.g., 15.08.2024\n",
        "        r\"\\b\\d{4}-\\d{2}-\\d{2}\\b|\"        # e.g., 2024-08-15\n",
        "        r\"\\b(19|20)\\d{2}\\b\"              # Four-digit years\n",
        "    ),\n",
        "\n",
        "    # German phone number format, must include country code\n",
        "    \"TELEFON\": r\"\\b\\+49\\s?\\d[\\d\\s/-]{6,}\\b\",\n",
        "\n",
        "    # Alphanumeric meter numbers, typically longer than 10 characters\n",
        "    \"ZÄHLERNUMMER\": r\"\\b[A-Z]{2}[A-Z0-9]{8,}\\b\",\n",
        "\n",
        "    # Payment amount pattern: includes currency keywords\n",
        "    \"ZAHLUNG\": r\"\\b\\d{1,5}[.,]\\d{2}\\s?(€|Euro|EUR|Cent)\\b\",\n",
        "\n",
        "    # Street pattern: must end with common street suffixes\n",
        "    \"STRASSE\": r\"\\b\\w+(straße|gasse|allee|weg|platz|str\\.|grund)\\b\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4cc5acd",
      "metadata": {
        "id": "f4cc5acd"
      },
      "source": [
        "PIIranha Spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "id": "12368595",
      "metadata": {
        "id": "12368595"
      },
      "outputs": [],
      "source": [
        "# Load the Piiranha model and tokenizer from HuggingFace\n",
        "model_name = \"iiiorg/piiranha-v1-detect-personal-information\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "\n",
        "# Select device: GPU if available, otherwise CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Function to extract entity spans from text using Piiranha\n",
        "def get_piiranha_spans(text):\n",
        "    # Tokenize input and get offset mappings (to map tokens back to character positions)\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, return_offsets_mapping=True)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    offset_mapping = inputs.pop(\"offset_mapping\")[0].tolist()\n",
        "\n",
        "    # Inference: get model predictions without gradient calculation\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)[0].tolist()\n",
        "\n",
        "    spans = []\n",
        "    current_label = None\n",
        "    current_start = None\n",
        "\n",
        "    # Iterate over each token and its offset\n",
        "    for i, (start, end) in enumerate(offset_mapping):\n",
        "        if start == end:\n",
        "            continue  # Skip special tokens like [CLS], [SEP]\n",
        "\n",
        "        # Get predicted label and map it to a simplified label name\n",
        "        raw_label = model.config.id2label[predictions[i]]\n",
        "        mapped_label = LABEL_MAP.get(raw_label, None)\n",
        "\n",
        "        # If the label is one of the target labels, track span start and continuation\n",
        "        if mapped_label in TARGET_LABELS:\n",
        "            if current_label == mapped_label:\n",
        "                continue  # Continue current span\n",
        "            else:\n",
        "                # If label changes, close previous span and start new one\n",
        "                if current_label is not None:\n",
        "                    spans.append({\"start\": current_start, \"end\": offset_mapping[i-1][1], \"label\": current_label})\n",
        "                current_label = mapped_label\n",
        "                current_start = start\n",
        "        else:\n",
        "            # If no valid label, close previous span if one was open\n",
        "            if current_label is not None:\n",
        "                spans.append({\"start\": current_start, \"end\": offset_mapping[i-1][1], \"label\": current_label})\n",
        "                current_label = None\n",
        "                current_start = None\n",
        "\n",
        "    # Finalize last span if still open\n",
        "    if current_label is not None:\n",
        "        spans.append({\"start\": current_start, \"end\": offset_mapping[-1][1], \"label\": current_label})\n",
        "\n",
        "    return spans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "899f7f6a",
      "metadata": {
        "id": "899f7f6a"
      },
      "source": [
        "SpaCy Ruler laden & Spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b11c54ec",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model with EntityRuler saved at: C:\\Users\\morit\\OneDrive\\Uni\\02_Master\\05_Studium\\02_Semester_II\\Data Analytics in Applications\\VSCode\\daia-eon\\notebooks\\3_model_training_and_testing\\spacy_pipeline\\piiranha_refinement\\custom_spacy_model_with_ruler\n"
          ]
        }
      ],
      "source": [
        "if use_ruler:\n",
        "    # Remove existing entity_ruler if present\n",
        "    if \"entity_ruler\" in nlp.pipe_names:\n",
        "        nlp.remove_pipe(\"entity_ruler\")\n",
        "\n",
        "    # Add a new entity_ruler before the NER component\n",
        "    ruler = nlp.add_pipe(\"entity_ruler\", before=\"ner\")\n",
        "\n",
        "    # Define patterns (Regex-based, no Gazetteer)\n",
        "    strasse_patterns = [\n",
        "        {\n",
        "            \"label\": \"STRASSE\",\n",
        "            \"pattern\": [\n",
        "                {\"TEXT\": {\"REGEX\": r\".*(straße|gasse|allee|weg|platz|str.|grund)$\"}},\n",
        "                {\"TEXT\": {\"REGEX\": r\"^\\d+[a-zA-Z]?$\"}}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    vertragsnummer_patterns = [\n",
        "        {\n",
        "            \"label\": \"VERTRAGSNUMMER\",\n",
        "            \"pattern\": [\n",
        "                {\"LOWER\": {\"IN\": [\"vertragsnummer\", \"vertragsnr.\", \"vnr\", \"vn\"]}},\n",
        "                {\"IS_PUNCT\": True, \"OP\": \"*\"},\n",
        "                {\"TEXT\": {\"REGEX\": r\"^\\d{6,12}\\\\.?$\"}}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    kundennummer_patterns = [\n",
        "        {\n",
        "            \"label\": \"KUNDENNUMMER\",\n",
        "            \"pattern\": [\n",
        "                {\"LOWER\": {\"IN\": [\"kundennummer\", \"kundennr.\", \"kdnr\", \"kd\"]}},\n",
        "                {\"IS_PUNCT\": True, \"OP\": \"*\"},\n",
        "                {\"TEXT\": {\"REGEX\": r\"^\\d{6,12}\\\\.?$\"}}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    zahlung_pattern = [\n",
        "        {\n",
        "            \"label\": \"ZAHLUNG\",\n",
        "            \"pattern\": [\n",
        "                {\"TEXT\": {\"REGEX\": r\"^\\d+[.,]?\\d{0,2}$\"}},\n",
        "                {\"TEXT\": {\"REGEX\": r\"^(\\u20ac|euro|eur)$\"}}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    email_pattern = [\n",
        "        {\n",
        "            \"label\": \"EMAIL\",\n",
        "            \"pattern\": [\n",
        "                {\"TEXT\": {\"REGEX\": r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w{2,}$\"}}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    telefon_pattern = [\n",
        "        {\n",
        "            \"label\": \"TELEFON\",\n",
        "            \"pattern\": [\n",
        "                {\"TEXT\": {\"REGEX\": r\"^(\\+49|0)[\\d\\s/-]{7,}$\"}}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    url_pattern = [\n",
        "        {\n",
        "            \"label\": \"LINK\",\n",
        "            \"pattern\": [\n",
        "                {\"TEXT\": {\"REGEX\": r\"^https?://[\\w\\-\\.]+\\.\\w{2,}(/[\\w\\-\\.]*)*$\"}}\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"label\": \"LINK\",\n",
        "            \"pattern\": [\n",
        "                {\"TEXT\": {\"REGEX\": r\"^www\\.[\\w\\-\\.]+\\.\\w{2,}(/[\\w\\-\\.]*)*$\"}}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    datum_pattern = [\n",
        "        {\n",
        "            \"label\": \"DATUM\",\n",
        "            \"pattern\": [\n",
        "                {\"TEXT\": {\"REGEX\": r\"^(\\d{1,2}[./-]){2}\\d{2,4}$\"}}\n",
        "            ]\n",
        "        },\n",
        "        {\n",
        "            \"label\": \"DATUM\",\n",
        "            \"pattern\": [\n",
        "                {\"TEXT\": {\"REGEX\": r\"^\\d{4}-\\d{2}-\\d{2}$\"}}\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Add all patterns to the ruler\n",
        "    ruler.add_patterns(\n",
        "        zahlung_pattern + url_pattern + email_pattern + telefon_pattern +\n",
        "        strasse_patterns + vertragsnummer_patterns + kundennummer_patterns + datum_pattern\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "id": "4b396a76",
      "metadata": {
        "id": "4b396a76"
      },
      "outputs": [],
      "source": [
        "def get_spacy_spans(text):\n",
        "    doc = nlp(text)\n",
        "    spans = []\n",
        "    for ent in doc.ents:\n",
        "        label = LABEL_MAP.get(ent.label_, ent.label_)\n",
        "        if label in TARGET_LABELS:\n",
        "            spans.append({\"start\": ent.start_char, \"end\": ent.end_char, \"label\": label})\n",
        "    return spans"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e73e8a11",
      "metadata": {
        "id": "e73e8a11"
      },
      "source": [
        "Regex Spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "id": "d80d052d",
      "metadata": {
        "id": "d80d052d"
      },
      "outputs": [],
      "source": [
        "def get_regex_spans(text):\n",
        "    spans = []\n",
        "    for raw_label, pattern in REGEX_PATTERNS.items():\n",
        "        mapped_label = LABEL_MAP.get(raw_label, raw_label)  # bleibt bei IBAN = IBAN\n",
        "        if mapped_label not in TARGET_LABELS:\n",
        "            continue\n",
        "        for match in re.finditer(pattern, text):\n",
        "            spans.append({\n",
        "                \"start\": match.start(),\n",
        "                \"end\": match.end(),\n",
        "                \"label\": mapped_label\n",
        "            })\n",
        "    return spans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "id": "9833fe90",
      "metadata": {
        "id": "9833fe90",
        "outputId": "add03921-f577-4f08-a1c8-8a4b994dfb1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "[{'start': 20, 'end': 24, 'label': 'VORNAME'}, {'start': 25, 'end': 28, 'label': 'NACHNAME'}, {'start': 48, 'end': 58, 'label': 'VERTRAGSNUMMER'}, {'start': 103, 'end': 113, 'label': 'EMAIL'}, {'start': 119, 'end': 135, 'label': 'TELEFONNUMMER'}, {'start': 154, 'end': 161, 'label': 'ZAHLUNG'}, {'start': 171, 'end': 173, 'label': 'ZAHLUNG'}]\n",
            "[{'start': 103, 'end': 113, 'label': 'EMAIL'}, {'start': 177, 'end': 181, 'label': 'DATUM'}]\n"
          ]
        }
      ],
      "source": [
        "# Beispieltext zum Testen\n",
        "sample_text = \"\"\"\n",
        "Sehr geehrter Herr John Doe,\n",
        "Ihre Kundennummer 4012345678 ist aktiv.\n",
        "Bitte kontaktieren Sie uns unter max@eon.de oder +49 171 1234567.\n",
        "Ihre Zahlung über 89,99 € wurde am 15-08-2024 verbucht.\n",
        "\"\"\"\n",
        "\n",
        "# PIIranha-Spans abrufen\n",
        "piiranha_spans = get_piiranha_spans(sample_text)\n",
        "spacy_spans = get_spacy_spans(sample_text)\n",
        "regex_spans = get_regex_spans(sample_text)\n",
        "\n",
        "# Ergebnisse ausgeben\n",
        "print(piiranha_spans)\n",
        "print(spacy_spans)\n",
        "print(regex_spans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "id": "de382f01",
      "metadata": {
        "id": "de382f01"
      },
      "outputs": [],
      "source": [
        "# 🧠 Optional: Merge overlapping or duplicate spans by sorting them\n",
        "def merge_spans(spans):\n",
        "    return sorted(spans, key=lambda x: x['start'])\n",
        "\n",
        "# 🔄 Resolve conflicts between overlapping spans based on priority\n",
        "def resolve_conflicts(spans):\n",
        "    # Sort spans: first by start index, then by descending length (longer first), then by priority\n",
        "    spans = sorted(\n",
        "        spans,\n",
        "        key=lambda x: (\n",
        "            x[\"start\"],\n",
        "            -(x[\"end\"] - x[\"start\"]),\n",
        "            -PRIORITY_MAP.get(x.get(\"source\", \"\"), 0)\n",
        "        )\n",
        "    )\n",
        "\n",
        "    resolved = []\n",
        "    occupied = set()\n",
        "\n",
        "    for span in spans:\n",
        "        span_range = set(range(span[\"start\"], span[\"end\"]))\n",
        "        conflict = False\n",
        "\n",
        "        for existing in resolved:\n",
        "            existing_range = set(range(existing[\"start\"], existing[\"end\"]))\n",
        "\n",
        "            # ❌ If spans overlap\n",
        "            if span_range & existing_range:\n",
        "                # ➕ If one span is fully inside the other → decide based on priority\n",
        "                if span[\"start\"] >= existing[\"start\"] and span[\"end\"] <= existing[\"end\"]:\n",
        "                    if PRIORITY_MAP[span[\"source\"]] > PRIORITY_MAP[existing[\"source\"]]:\n",
        "                        resolved.remove(existing)\n",
        "                        break\n",
        "                    else:\n",
        "                        conflict = True\n",
        "                        break\n",
        "                elif existing[\"start\"] >= span[\"start\"] and existing[\"end\"] <= span[\"end\"]:\n",
        "                    if PRIORITY_MAP[span[\"source\"]] < PRIORITY_MAP[existing[\"source\"]]:\n",
        "                        conflict = True\n",
        "                        break\n",
        "                    else:\n",
        "                        resolved.remove(existing)\n",
        "                        break\n",
        "                else:\n",
        "                    # True overlap, not nested – reject current span\n",
        "                    conflict = True\n",
        "                    break\n",
        "\n",
        "        if not conflict:\n",
        "            resolved.append(span)\n",
        "            occupied.update(span_range)\n",
        "\n",
        "    return resolved\n",
        "\n",
        "# 🔐 Apply final redaction using label numbering (e.g., NAME_1, NAME_2, ...)\n",
        "def apply_final_redaction(text, spans):\n",
        "    spans = sorted(spans, key=lambda x: x[\"start\"])\n",
        "    redacted = []\n",
        "    last_index = 0\n",
        "    label_counter = defaultdict(int)\n",
        "\n",
        "    for span in spans:\n",
        "        label = span[\"label\"]\n",
        "        label_counter[label] += 1\n",
        "        label_with_id = f\"{label}_{label_counter[label]}\"\n",
        "\n",
        "        # Keep text before the span\n",
        "        redacted.append(text[last_index:span[\"start\"]])\n",
        "        # Insert replacement token\n",
        "        redacted.append(f\"[{label_with_id}]\")\n",
        "        # Update position pointer\n",
        "        last_index = span[\"end\"]\n",
        "\n",
        "    # Append any remaining text\n",
        "    redacted.append(text[last_index:])\n",
        "    return ''.join(redacted)\n",
        "\n",
        "# 🧩 Main masking function using multiple components (e.g., regex, spacy, piiranha)\n",
        "def mask_text_with_all(text, components=[\"regex\"]):\n",
        "    all_spans = []\n",
        "\n",
        "    if \"regex\" in components:\n",
        "        for span in get_regex_spans(text):\n",
        "            span[\"source\"] = \"regex\"\n",
        "            all_spans.append(span)\n",
        "\n",
        "    if \"piiranha\" in components:\n",
        "        for span in get_piiranha_spans(text):\n",
        "            span[\"source\"] = \"piiranha\"\n",
        "            all_spans.append(span)\n",
        "\n",
        "    if \"spacy\" in components:\n",
        "        for span in get_spacy_spans(text):\n",
        "            span[\"source\"] = \"spacy\"\n",
        "            all_spans.append(span)\n",
        "\n",
        "    # 🔧 Resolve span conflicts and apply redaction\n",
        "    spans = resolve_conflicts(all_spans)\n",
        "    merged = merge_spans(spans)\n",
        "    return apply_final_redaction(text, merged)\n",
        "\n",
        "# 🎯 Mask text using only a single component (for testing or analysis)\n",
        "def mask_text_with_single_component(text, component=\"regex\"):\n",
        "    if component == \"regex\":\n",
        "        all_spans = get_regex_spans(text)\n",
        "    elif component == \"piiranha\":\n",
        "        all_spans = get_piiranha_spans(text)\n",
        "    elif component == \"spacy\":\n",
        "        all_spans = get_spacy_spans(text)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown component: {component}\")\n",
        "\n",
        "    # Optionally resolve internal conflicts within single component spans\n",
        "    spans = resolve_conflicts(all_spans)\n",
        "    merged = merge_spans(spans)\n",
        "\n",
        "    # Return the redacted version of the input text\n",
        "    return apply_final_redaction(text, merged)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "id": "42b3e31e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation results saved to: evaluation_spacy_ruler_orginal.csv\n"
          ]
        }
      ],
      "source": [
        "# Load ground truth test data\n",
        "with open(\"../../../../data/original/ground_truth_split/test_norm.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "# Helper function: convert span dictionary to tuple\n",
        "def to_tuple(span):\n",
        "    return (span[\"start\"], span[\"end\"], span[\"label\"])\n",
        "\n",
        "# Evaluate predicted spans against gold standard\n",
        "def evaluate_entities(pred_fn, data, threshold=0.8):\n",
        "    stats = defaultdict(lambda: {\"tp\": 0, \"fp\": 0, \"fn\": 0})\n",
        "    total_tp = total_fp = total_fn = 0\n",
        "\n",
        "    for entry in data:\n",
        "        text = entry[\"text\"]\n",
        "        gold_spans = [to_tuple(s) for s in entry[\"labels\"]]\n",
        "        pred_spans = [to_tuple(s) for s in pred_fn(text)]\n",
        "        matched_gold = set()\n",
        "        matched_pred = set()\n",
        "\n",
        "        # Try to match each predicted span with a gold span using Jaccard similarity\n",
        "        for pi, p in enumerate(pred_spans):\n",
        "            best_match = None\n",
        "            best_overlap = 0\n",
        "            for gi, g in enumerate(gold_spans):\n",
        "                if g[2] != p[2]:  # Only match if labels are the same\n",
        "                    continue\n",
        "                overlap = max(0, min(p[1], g[1]) - max(p[0], g[0]))\n",
        "                union = max(p[1], g[1]) - min(p[0], g[0])\n",
        "                jaccard = overlap / union if union > 0 else 0\n",
        "                if jaccard >= threshold and jaccard > best_overlap:\n",
        "                    best_overlap = jaccard\n",
        "                    best_match = gi\n",
        "            if best_match is not None:\n",
        "                matched_gold.add(best_match)\n",
        "                matched_pred.add(pi)\n",
        "                stats[p[2]][\"tp\"] += 1\n",
        "                total_tp += 1\n",
        "\n",
        "        # Count false positives: predicted spans without gold match\n",
        "        for i, p in enumerate(pred_spans):\n",
        "            if i not in matched_pred:\n",
        "                stats[p[2]][\"fp\"] += 1\n",
        "                total_fp += 1\n",
        "\n",
        "        # Count false negatives: gold spans without prediction\n",
        "        for i, g in enumerate(gold_spans):\n",
        "            if i not in matched_gold:\n",
        "                stats[g[2]][\"fn\"] += 1\n",
        "                total_fn += 1\n",
        "\n",
        "    # Convert statistics to rows for DataFrame\n",
        "    rows = []\n",
        "    for label, counts in stats.items():\n",
        "        tp, fp, fn = counts[\"tp\"], counts[\"fp\"], counts[\"fn\"]\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall    = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1        = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        rows.append({\n",
        "            \"component\": \"Combined\",\n",
        "            \"label\": label,\n",
        "            \"tp\": tp,\n",
        "            \"fp\": fp,\n",
        "            \"fn\": fn,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"f1\": f1\n",
        "        })\n",
        "\n",
        "    # Add overall performance row\n",
        "    overall_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0\n",
        "    overall_recall    = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0\n",
        "    overall_f1        = 2 * overall_precision * overall_recall / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0\n",
        "\n",
        "    rows.append({\n",
        "        \"component\": \"Combined\",\n",
        "        \"label\": \"OVERALL\",\n",
        "        \"tp\": total_tp,\n",
        "        \"fp\": total_fp,\n",
        "        \"fn\": total_fn,\n",
        "        \"precision\": overall_precision,\n",
        "        \"recall\": overall_recall,\n",
        "        \"f1\": overall_f1\n",
        "    })\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# Prediction function with configurable component selection\n",
        "def run_combined_spans(text, use_spacy=use_spacy, use_regex=use_regex, use_piiranha=use_piiranha):\n",
        "    all_spans = []\n",
        "\n",
        "    if use_regex:\n",
        "        for span in get_regex_spans(text):\n",
        "            span[\"source\"] = \"regex\"\n",
        "            all_spans.append(span)\n",
        "\n",
        "    if use_piiranha:\n",
        "        for span in get_piiranha_spans(text):\n",
        "            span[\"source\"] = \"piiranha\"\n",
        "            all_spans.append(span)\n",
        "\n",
        "    if use_spacy:\n",
        "        for span in get_spacy_spans(text):\n",
        "            span[\"source\"] = \"spacy\"\n",
        "            all_spans.append(span)\n",
        "\n",
        "    resolved = resolve_conflicts(all_spans)\n",
        "    return merge_spans(resolved)\n",
        "\n",
        "\n",
        "# Define the prediction function with the flags\n",
        "df_eval = evaluate_entities(\n",
        "    lambda text: run_combined_spans(\n",
        "        text,\n",
        "        use_spacy=use_spacy,\n",
        "        use_regex=use_regex,\n",
        "        use_piiranha=use_piiranha\n",
        "    ),\n",
        "    test_data,\n",
        "    threshold=0.5\n",
        ")\n",
        "\n",
        "# Build filename based on settings\n",
        "used_components = []\n",
        "if use_spacy: used_components.append(\"spacy\")\n",
        "if use_regex: used_components.append(\"regex\")\n",
        "if use_piiranha: used_components.append(\"piiranha\")\n",
        "components_str = \"_\".join(used_components) if used_components else \"none\"\n",
        "\n",
        "ruler_str = \"ruler\" if use_ruler else \"no_ruler\"\n",
        "\n",
        "filename = f\"evaluation_{components_str}_{ruler_str}_{nlp_name}.csv\"\n",
        "\n",
        "# Save evaluation results\n",
        "df_eval.to_csv(filename, index=False)\n",
        "print(f\"Evaluation results saved to: {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "id": "eeb8ee11",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>component</th>\n",
              "      <th>label</th>\n",
              "      <th>tp</th>\n",
              "      <th>fp</th>\n",
              "      <th>fn</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Combined</td>\n",
              "      <td>GESENDET_MIT</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Combined</td>\n",
              "      <td>LINK</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Combined</td>\n",
              "      <td>VERTRAGSNUMMER</td>\n",
              "      <td>21</td>\n",
              "      <td>6</td>\n",
              "      <td>19</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.626866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Combined</td>\n",
              "      <td>ZAHLUNG</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Combined</td>\n",
              "      <td>VORNAME</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Combined</td>\n",
              "      <td>NACHNAME</td>\n",
              "      <td>57</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.966102</td>\n",
              "      <td>0.934426</td>\n",
              "      <td>0.950000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Combined</td>\n",
              "      <td>DATUM</td>\n",
              "      <td>26</td>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>0.702703</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.776119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Combined</td>\n",
              "      <td>TITEL</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Combined</td>\n",
              "      <td>IBAN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Combined</td>\n",
              "      <td>ZÄHLERNUMMER</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Combined</td>\n",
              "      <td>TELEFONNUMMER</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.592593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Combined</td>\n",
              "      <td>ZÄHLERSTAND</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Combined</td>\n",
              "      <td>FIRMA</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Combined</td>\n",
              "      <td>POSTLEITZAHL</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Combined</td>\n",
              "      <td>STRASSE</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.941176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Combined</td>\n",
              "      <td>EMAIL</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.769231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Combined</td>\n",
              "      <td>WOHNORT</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Combined</td>\n",
              "      <td>HAUSNUMMER</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.740741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Combined</td>\n",
              "      <td>FAX</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Combined</td>\n",
              "      <td>BANK</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Combined</td>\n",
              "      <td>OVERALL</td>\n",
              "      <td>254</td>\n",
              "      <td>41</td>\n",
              "      <td>66</td>\n",
              "      <td>0.861017</td>\n",
              "      <td>0.793750</td>\n",
              "      <td>0.826016</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   component           label   tp  fp  fn  precision    recall        f1\n",
              "0   Combined    GESENDET_MIT    5   1   1   0.833333  0.833333  0.833333\n",
              "1   Combined            LINK    3   1   0   0.750000  1.000000  0.857143\n",
              "2   Combined  VERTRAGSNUMMER   21   6  19   0.777778  0.525000  0.626866\n",
              "3   Combined         ZAHLUNG    5   1   3   0.833333  0.625000  0.714286\n",
              "4   Combined         VORNAME   57   0   0   1.000000  1.000000  1.000000\n",
              "5   Combined        NACHNAME   57   2   4   0.966102  0.934426  0.950000\n",
              "6   Combined           DATUM   26  11   4   0.702703  0.866667  0.776119\n",
              "7   Combined           TITEL    8   0   0   1.000000  1.000000  1.000000\n",
              "8   Combined            IBAN    0   0   4   0.000000  0.000000  0.000000\n",
              "9   Combined    ZÄHLERNUMMER    2   2   4   0.500000  0.333333  0.400000\n",
              "10  Combined   TELEFONNUMMER    8   5   6   0.615385  0.571429  0.592593\n",
              "11  Combined     ZÄHLERSTAND    0   0   3   0.000000  0.000000  0.000000\n",
              "12  Combined           FIRMA    0   3   6   0.000000  0.000000  0.000000\n",
              "13  Combined    POSTLEITZAHL   16   0   0   1.000000  1.000000  1.000000\n",
              "14  Combined         STRASSE   16   2   0   0.888889  1.000000  0.941176\n",
              "15  Combined           EMAIL    5   3   0   0.625000  1.000000  0.769231\n",
              "16  Combined         WOHNORT   15   3   3   0.833333  0.833333  0.833333\n",
              "17  Combined      HAUSNUMMER   10   1   6   0.909091  0.625000  0.740741\n",
              "18  Combined             FAX    0   0   2   0.000000  0.000000  0.000000\n",
              "19  Combined            BANK    0   0   1   0.000000  0.000000  0.000000\n",
              "20  Combined         OVERALL  254  41  66   0.861017  0.793750  0.826016"
            ]
          },
          "execution_count": 203,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_eval"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.11.9)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
