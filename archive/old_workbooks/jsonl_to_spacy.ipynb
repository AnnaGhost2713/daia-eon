{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-04T13:56:51.074451Z",
     "start_time": "2025-06-04T13:56:51.072634Z"
    }
   },
   "source": [
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ðŸ““ Notebook: Konvertierung von JSONL zu spaCy .spacy Format\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.tokens import DocBin, Doc\n",
    "\n",
    "# Sprache setzen (deutsch)\n",
    "nlp = spacy.blank(\"de\")  # Leeres spaCy-Modell\n",
    "\n",
    "# Pfade\n",
    "train_path = Path(\"../old_data/converted_piranha/train_converted_piranha.jsonl\")\n",
    "eval_path = Path(\"../old_data/converted_piranha/eval_converted_piranha.jsonl\")\n",
    "output_train = Path(\"../data/train.spacy\")\n",
    "output_dev = Path(\"../data/dev.spacy\")\n",
    "\n",
    "# Funktion zur Konvertierung einer JSONL-Datei in DocBin\n",
    "def convert_to_spacy(input_path, output_path):\n",
    "    doc_bin = DocBin()\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            example = json.loads(line)\n",
    "            tokens = example[\"tokens\"]\n",
    "            labels = example[\"labels\"]\n",
    "\n",
    "            # Entferne ggf. [CLS] und [SEP] Token (aus BERT Tokenizer)\n",
    "            if tokens[0] == \"[CLS]\":\n",
    "                tokens = tokens[1:]\n",
    "                labels = labels[1:]\n",
    "            if tokens[-1] == \"[SEP]\":\n",
    "                tokens = tokens[:-1]\n",
    "                labels = labels[:-1]\n",
    "\n",
    "            # spaCy-Dokument erstellen\n",
    "            doc = Doc(nlp.vocab, words=tokens)\n",
    "\n",
    "            # EntitÃ¤ten als Spans setzen\n",
    "            ents = []\n",
    "            start = None\n",
    "            label = None\n",
    "            for i, tag in enumerate(labels):\n",
    "                if tag.startswith(\"B-\"):\n",
    "                    if start is not None:\n",
    "                        ents.append(doc.char_span(doc[start].idx, doc[i - 1].idx + len(doc[i - 1]), label=label))\n",
    "                    start = i\n",
    "                    label = tag[2:]\n",
    "                elif tag.startswith(\"I-\") and label is not None:\n",
    "                    continue\n",
    "                else:\n",
    "                    if start is not None:\n",
    "                        ents.append(doc.char_span(doc[start].idx, doc[i - 1].idx + len(doc[i - 1]), label=label))\n",
    "                        start = None\n",
    "                        label = None\n",
    "            if start is not None:\n",
    "                ents.append(doc.char_span(doc[start].idx, doc[len(labels) - 1].idx + len(doc[len(labels) - 1]), label=label))\n",
    "\n",
    "            doc.ents = [e for e in ents if e is not None]\n",
    "            doc_bin.add(doc)\n",
    "\n",
    "    doc_bin.to_disk(output_path)\n",
    "    print(f\"Gespeichert: {output_path}\")\n",
    "\n",
    "# Konvertieren\n",
    "convert_to_spacy(train_path, output_train)\n",
    "convert_to_spacy(eval_path, output_dev)\n"
   ],
   "id": "b59daa4d39bc4a43"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
